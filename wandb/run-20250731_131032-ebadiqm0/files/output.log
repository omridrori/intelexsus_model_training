  0%|                                                                    | 0/1825794 [00:00<?, ?it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
  0%|                                                      | 251/1825794 [04:08<222:16:24,  2.28it/s]Traceback (most recent call last):
{'loss': 11.0395, 'grad_norm': 16.5982723236084, 'learning_rate': 9.584839522401139e-10, 'epoch': 0.0}
{'loss': 12.368, 'grad_norm': 14.390482902526855, 'learning_rate': 2.053894183371673e-09, 'epoch': 0.0}
{'loss': 12.8072, 'grad_norm': 17.378446578979492, 'learning_rate': 3.1493044145032315e-09, 'epoch': 0.0}
{'loss': 14.2087, 'grad_norm': 17.367700576782227, 'learning_rate': 4.24471464563479e-09, 'epoch': 0.0}
{'loss': 12.4888, 'grad_norm': 16.26512908935547, 'learning_rate': 5.340124876766349e-09, 'epoch': 0.0}
{'loss': 12.5507, 'grad_norm': 19.976768493652344, 'learning_rate': 6.435535107897908e-09, 'epoch': 0.0}
{'loss': 12.6104, 'grad_norm': 16.95615005493164, 'learning_rate': 7.530945339029467e-09, 'epoch': 0.0}
{'loss': 12.5308, 'grad_norm': 14.24311351776123, 'learning_rate': 8.626355570161026e-09, 'epoch': 0.0}
{'loss': 12.5108, 'grad_norm': 19.423423767089844, 'learning_rate': 9.721765801292585e-09, 'epoch': 0.0}
{'loss': 13.9901, 'grad_norm': 16.97055435180664, 'learning_rate': 1.0817176032424143e-08, 'epoch': 0.0}
{'loss': 10.9293, 'grad_norm': 14.410248756408691, 'learning_rate': 1.1912586263555702e-08, 'epoch': 0.0}
{'loss': 12.8023, 'grad_norm': 13.586634635925293, 'learning_rate': 1.300799649468726e-08, 'epoch': 0.0}
{'loss': 10.416, 'grad_norm': 18.139869689941406, 'learning_rate': 1.410340672581882e-08, 'epoch': 0.0}
{'loss': 12.1296, 'grad_norm': 17.157299041748047, 'learning_rate': 1.5198816956950378e-08, 'epoch': 0.0}
{'loss': 13.3486, 'grad_norm': 15.417323112487793, 'learning_rate': 1.6294227188081935e-08, 'epoch': 0.0}
{'loss': 12.5323, 'grad_norm': 19.08615493774414, 'learning_rate': 1.7389637419213496e-08, 'epoch': 0.0}
{'loss': 10.9906, 'grad_norm': 17.45389175415039, 'learning_rate': 1.8485047650345053e-08, 'epoch': 0.0}
{'loss': 11.4771, 'grad_norm': 17.673826217651367, 'learning_rate': 1.9580457881476613e-08, 'epoch': 0.0}
{'loss': 10.4864, 'grad_norm': 15.334266662597656, 'learning_rate': 2.067586811260817e-08, 'epoch': 0.0}
{'loss': 14.1904, 'grad_norm': 15.843952178955078, 'learning_rate': 2.177127834373973e-08, 'epoch': 0.0}
{'loss': 11.4451, 'grad_norm': 18.832317352294922, 'learning_rate': 2.2866688574871288e-08, 'epoch': 0.0}
{'loss': 11.2661, 'grad_norm': 13.719402313232422, 'learning_rate': 2.3962098806002848e-08, 'epoch': 0.0}
{'loss': 11.5046, 'grad_norm': 17.44713592529297, 'learning_rate': 2.5057509037134408e-08, 'epoch': 0.0}
{'loss': 11.4619, 'grad_norm': 17.099441528320312, 'learning_rate': 2.6152919268265965e-08, 'epoch': 0.0}
{'loss': 10.4363, 'grad_norm': 12.703069686889648, 'learning_rate': 2.7248329499397526e-08, 'epoch': 0.0}
{'loss': 10.9562, 'grad_norm': 16.709304809570312, 'learning_rate': 2.8343739730529083e-08, 'epoch': 0.0}
{'loss': 11.2987, 'grad_norm': 17.607847213745117, 'learning_rate': 2.9439149961660643e-08, 'epoch': 0.0}
{'loss': 12.5829, 'grad_norm': 15.39954948425293, 'learning_rate': 3.0534560192792203e-08, 'epoch': 0.0}
{'loss': 15.6753, 'grad_norm': 16.232784271240234, 'learning_rate': 3.162997042392376e-08, 'epoch': 0.0}
{'loss': 10.4088, 'grad_norm': 14.159330368041992, 'learning_rate': 3.272538065505532e-08, 'epoch': 0.0}
{'loss': 11.3403, 'grad_norm': 17.958297729492188, 'learning_rate': 3.382079088618688e-08, 'epoch': 0.0}
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\train_model.py", line 67, in <module>
    main()
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\train_model.py", line 51, in main
    run_training(
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\training_utils.py", line 93, in run_training
    compute_metrics=compute_metrics if eval_dataset else None,
    ^^^^^^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 2237, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 2577, in _inner_training_loop
    with context():
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\contextlib.py", line 141, in __exit__
    def __exit__(self, typ, value, traceback):

KeyboardInterrupt
