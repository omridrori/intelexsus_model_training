  0%|                                                                                                                | 0/2738688 [00:00<?, ?it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
                                                                                                                                                 
{'loss': 11.1305, 'grad_norm': 10.355751037597656, 'learning_rate': 4.999992697233128e-05, 'epoch': 0.0}
{'loss': 10.2759, 'grad_norm': 10.458650588989258, 'learning_rate': 4.999983568774538e-05, 'epoch': 0.0}
{'loss': 16.0245, 'grad_norm': 8.936306953430176, 'learning_rate': 4.999974440315947e-05, 'epoch': 0.0}
{'loss': 13.2645, 'grad_norm': 10.510656356811523, 'learning_rate': 4.999965311857357e-05, 'epoch': 0.0}
{'loss': 13.9644, 'grad_norm': 7.921909809112549, 'learning_rate': 4.9999561833987666e-05, 'epoch': 0.0}
{'loss': 11.2283, 'grad_norm': 8.435081481933594, 'learning_rate': 4.9999470549401764e-05, 'epoch': 0.0}
{'loss': 22.7648, 'grad_norm': 5.984673023223877, 'learning_rate': 4.9999379264815856e-05, 'epoch': 0.0}
{'loss': 13.3618, 'grad_norm': 8.049025535583496, 'learning_rate': 4.9999287980229954e-05, 'epoch': 0.0}
{'loss': 15.9467, 'grad_norm': 7.918441295623779, 'learning_rate': 4.9999196695644046e-05, 'epoch': 0.0}
{'loss': 13.7009, 'grad_norm': 7.15615701675415, 'learning_rate': 4.9999105411058144e-05, 'epoch': 0.0}
{'loss': 14.2193, 'grad_norm': 8.599515914916992, 'learning_rate': 4.9999014126472236e-05, 'epoch': 0.0}
{'loss': 13.9031, 'grad_norm': 10.48659610748291, 'learning_rate': 4.9998922841886335e-05, 'epoch': 0.0}
{'loss': 11.4484, 'grad_norm': 8.745560646057129, 'learning_rate': 4.999883155730043e-05, 'epoch': 0.0}
{'loss': 10.5361, 'grad_norm': 7.837714195251465, 'learning_rate': 4.999874027271453e-05, 'epoch': 0.0}
{'loss': 15.9648, 'grad_norm': 8.400225639343262, 'learning_rate': 4.999864898812863e-05, 'epoch': 0.0}
{'loss': 13.3929, 'grad_norm': 7.769842147827148, 'learning_rate': 4.999855770354272e-05, 'epoch': 0.0}
{'loss': 14.2401, 'grad_norm': 8.738166809082031, 'learning_rate': 4.999846641895682e-05, 'epoch': 0.0}
{'loss': 16.4479, 'grad_norm': 6.756129741668701, 'learning_rate': 4.999837513437091e-05, 'epoch': 0.0}
{'loss': 14.1553, 'grad_norm': 6.12105655670166, 'learning_rate': 4.999828384978501e-05, 'epoch': 0.0}
{'loss': 11.5506, 'grad_norm': 4.858640193939209, 'learning_rate': 4.99981925651991e-05, 'epoch': 0.0}
{'loss': 17.1456, 'grad_norm': 8.299814224243164, 'learning_rate': 4.99981012806132e-05, 'epoch': 0.0}
{'loss': 10.8562, 'grad_norm': 6.325104236602783, 'learning_rate': 4.999800999602729e-05, 'epoch': 0.0}
{'loss': 17.8587, 'grad_norm': 7.813632965087891, 'learning_rate': 4.999791871144139e-05, 'epoch': 0.0}
{'loss': 15.1744, 'grad_norm': 8.446586608886719, 'learning_rate': 4.999782742685549e-05, 'epoch': 0.0}
{'loss': 25.1085, 'grad_norm': 8.801904678344727, 'learning_rate': 4.999773614226959e-05, 'epoch': 0.0}
{'loss': 10.8693, 'grad_norm': 8.312660217285156, 'learning_rate': 4.9997644857683686e-05, 'epoch': 0.0}
{'loss': 11.6177, 'grad_norm': 6.501137733459473, 'learning_rate': 4.999755357309778e-05, 'epoch': 0.0}
{'loss': 9.7841, 'grad_norm': 6.567753314971924, 'learning_rate': 4.9997462288511876e-05, 'epoch': 0.0}
{'loss': 15.1325, 'grad_norm': 6.298566818237305, 'learning_rate': 4.999737100392597e-05, 'epoch': 0.0}
{'loss': 10.5362, 'grad_norm': 8.242691993713379, 'learning_rate': 4.9997279719340066e-05, 'epoch': 0.0}
{'loss': 13.7693, 'grad_norm': 5.531765460968018, 'learning_rate': 4.999718843475416e-05, 'epoch': 0.0}
{'loss': 9.6131, 'grad_norm': 7.823294639587402, 'learning_rate': 4.999709715016826e-05, 'epoch': 0.0}
{'loss': 8.9172, 'grad_norm': 7.271173000335693, 'learning_rate': 4.9997005865582355e-05, 'epoch': 0.0}
{'loss': 13.5628, 'grad_norm': 7.154171943664551, 'learning_rate': 4.9996914580996454e-05, 'epoch': 0.0}
{'loss': 8.1995, 'grad_norm': 7.608196258544922, 'learning_rate': 4.9996823296410545e-05, 'epoch': 0.0}
{'loss': 16.8938, 'grad_norm': 7.788903713226318, 'learning_rate': 4.9996732011824644e-05, 'epoch': 0.0}
{'loss': 10.4292, 'grad_norm': 8.721982955932617, 'learning_rate': 4.9996640727238735e-05, 'epoch': 0.0}
{'loss': 11.2272, 'grad_norm': 5.545406818389893, 'learning_rate': 4.9996549442652834e-05, 'epoch': 0.0}
{'loss': 15.8669, 'grad_norm': 6.64831018447876, 'learning_rate': 4.999645815806693e-05, 'epoch': 0.0}
{'loss': 15.912, 'grad_norm': 8.536730766296387, 'learning_rate': 4.9996366873481024e-05, 'epoch': 0.0}
{'loss': 10.8774, 'grad_norm': 6.441521644592285, 'learning_rate': 4.999627558889512e-05, 'epoch': 0.0}
{'loss': 9.4268, 'grad_norm': 5.926734447479248, 'learning_rate': 4.999618430430922e-05, 'epoch': 0.0}
{'loss': 10.0429, 'grad_norm': 7.273916244506836, 'learning_rate': 4.999609301972332e-05, 'epoch': 0.0}
{'loss': 9.1914, 'grad_norm': 7.8491716384887695, 'learning_rate': 4.999600173513741e-05, 'epoch': 0.0}
{'loss': 14.493, 'grad_norm': 7.500688076019287, 'learning_rate': 4.999591045055151e-05, 'epoch': 0.0}
{'loss': 9.3309, 'grad_norm': 6.6973090171813965, 'learning_rate': 4.99958191659656e-05, 'epoch': 0.0}
{'loss': 8.6855, 'grad_norm': 8.290528297424316, 'learning_rate': 4.99957278813797e-05, 'epoch': 0.0}
{'loss': 8.8043, 'grad_norm': 7.016682147979736, 'learning_rate': 4.999563659679379e-05, 'epoch': 0.0}
{'loss': 12.2419, 'grad_norm': 6.206503868103027, 'learning_rate': 4.999554531220789e-05, 'epoch': 0.0}
{'loss': 7.6813, 'grad_norm': 6.951176643371582, 'learning_rate': 4.999545402762199e-05, 'epoch': 0.0}
{'loss': 10.6788, 'grad_norm': 7.628696441650391, 'learning_rate': 4.999536274303609e-05, 'epoch': 0.0}
{'loss': 12.1998, 'grad_norm': 6.618818759918213, 'learning_rate': 4.9995271458450185e-05, 'epoch': 0.0}
{'loss': 8.8531, 'grad_norm': 6.819949626922607, 'learning_rate': 4.999518017386428e-05, 'epoch': 0.0}
{'loss': 8.631, 'grad_norm': 9.899321556091309, 'learning_rate': 4.9995088889278376e-05, 'epoch': 0.0}
{'loss': 9.3658, 'grad_norm': 5.265326023101807, 'learning_rate': 4.999499760469247e-05, 'epoch': 0.0}
{'loss': 20.6179, 'grad_norm': 7.009646415710449, 'learning_rate': 4.9994906320106566e-05, 'epoch': 0.0}
{'loss': 16.37, 'grad_norm': 8.22311782836914, 'learning_rate': 4.999481503552066e-05, 'epoch': 0.0}
{'loss': 11.4071, 'grad_norm': 6.74918794631958, 'learning_rate': 4.9994723750934756e-05, 'epoch': 0.0}
{'loss': 11.2513, 'grad_norm': 6.4065752029418945, 'learning_rate': 4.999463246634885e-05, 'epoch': 0.0}
{'loss': 10.558, 'grad_norm': 6.225197792053223, 'learning_rate': 4.9994541181762946e-05, 'epoch': 0.0}
{'loss': 14.2264, 'grad_norm': 7.336432933807373, 'learning_rate': 4.9994449897177045e-05, 'epoch': 0.0}
{'loss': 16.5806, 'grad_norm': 5.677375793457031, 'learning_rate': 4.999435861259114e-05, 'epoch': 0.0}
{'loss': 13.1354, 'grad_norm': 8.431787490844727, 'learning_rate': 4.9994267328005235e-05, 'epoch': 0.0}
{'loss': 14.5785, 'grad_norm': 6.6175456047058105, 'learning_rate': 4.999417604341933e-05, 'epoch': 0.0}
{'loss': 12.799, 'grad_norm': 5.44063138961792, 'learning_rate': 4.999408475883343e-05, 'epoch': 0.0}
{'loss': 22.6673, 'grad_norm': 6.447381496429443, 'learning_rate': 4.9993993474247523e-05, 'epoch': 0.0}
{'loss': 15.7458, 'grad_norm': 3.812668800354004, 'learning_rate': 4.999390218966162e-05, 'epoch': 0.0}
{'loss': 16.4113, 'grad_norm': 5.930346965789795, 'learning_rate': 4.9993810905075714e-05, 'epoch': 0.0}
{'loss': 11.6403, 'grad_norm': 6.86433219909668, 'learning_rate': 4.999371962048981e-05, 'epoch': 0.0}
{'loss': 15.6184, 'grad_norm': 7.461651802062988, 'learning_rate': 4.999362833590391e-05, 'epoch': 0.0}
{'loss': 18.419, 'grad_norm': 5.499693393707275, 'learning_rate': 4.999353705131801e-05, 'epoch': 0.0}
{'loss': 12.3306, 'grad_norm': 5.865890026092529, 'learning_rate': 4.99934457667321e-05, 'epoch': 0.0}
{'loss': 11.146, 'grad_norm': 7.555119514465332, 'learning_rate': 4.99933544821462e-05, 'epoch': 0.0}
{'loss': 12.1457, 'grad_norm': 7.336156845092773, 'learning_rate': 4.999326319756029e-05, 'epoch': 0.0}
{'loss': 16.3757, 'grad_norm': 6.924222469329834, 'learning_rate': 4.999317191297439e-05, 'epoch': 0.0}
{'loss': 9.4826, 'grad_norm': 7.041510105133057, 'learning_rate': 4.999308062838849e-05, 'epoch': 0.0}
{'loss': 11.6467, 'grad_norm': 8.11829948425293, 'learning_rate': 4.999298934380258e-05, 'epoch': 0.0}
{'loss': 10.816, 'grad_norm': 6.859933376312256, 'learning_rate': 4.999289805921668e-05, 'epoch': 0.0}
{'loss': 14.4045, 'grad_norm': 5.382504940032959, 'learning_rate': 4.9992806774630776e-05, 'epoch': 0.0}
{'loss': 10.8858, 'grad_norm': 5.269960880279541, 'learning_rate': 4.9992715490044875e-05, 'epoch': 0.0}
{'loss': 10.761, 'grad_norm': 8.07331371307373, 'learning_rate': 4.999262420545897e-05, 'epoch': 0.0}
{'loss': 13.2201, 'grad_norm': 5.952174186706543, 'learning_rate': 4.9992532920873065e-05, 'epoch': 0.0}
{'loss': 12.036, 'grad_norm': 6.922147750854492, 'learning_rate': 4.999244163628716e-05, 'epoch': 0.0}
{'loss': 11.5559, 'grad_norm': 8.680403709411621, 'learning_rate': 4.9992350351701255e-05, 'epoch': 0.0}
{'loss': 10.5663, 'grad_norm': 6.46722936630249, 'learning_rate': 4.999225906711535e-05, 'epoch': 0.0}
{'loss': 11.5367, 'grad_norm': 7.521543979644775, 'learning_rate': 4.9992167782529445e-05, 'epoch': 0.0}
{'loss': 11.5187, 'grad_norm': 7.353007793426514, 'learning_rate': 4.9992076497943544e-05, 'epoch': 0.0}
{'loss': 15.3361, 'grad_norm': 5.771025657653809, 'learning_rate': 4.999198521335764e-05, 'epoch': 0.0}
{'loss': 10.2986, 'grad_norm': 7.49556303024292, 'learning_rate': 4.999189392877174e-05, 'epoch': 0.0}
{'loss': 14.162, 'grad_norm': 6.1858720779418945, 'learning_rate': 4.999180264418583e-05, 'epoch': 0.0}
{'loss': 10.9594, 'grad_norm': 5.811623573303223, 'learning_rate': 4.999171135959993e-05, 'epoch': 0.0}
{'loss': 10.1684, 'grad_norm': 6.629032611846924, 'learning_rate': 4.999162007501402e-05, 'epoch': 0.0}
{'loss': 7.8069, 'grad_norm': 7.370633602142334, 'learning_rate': 4.999152879042812e-05, 'epoch': 0.0}
{'loss': 14.7843, 'grad_norm': 5.956596374511719, 'learning_rate': 4.999143750584221e-05, 'epoch': 0.0}
{'loss': 9.0318, 'grad_norm': 6.711220741271973, 'learning_rate': 4.999134622125631e-05, 'epoch': 0.0}
{'loss': 8.5418, 'grad_norm': 6.715198993682861, 'learning_rate': 4.99912549366704e-05, 'epoch': 0.0}
{'loss': 11.9584, 'grad_norm': 5.663300514221191, 'learning_rate': 4.999116365208451e-05, 'epoch': 0.0}
{'loss': 11.1282, 'grad_norm': 5.916241645812988, 'learning_rate': 4.99910723674986e-05, 'epoch': 0.0}
{'loss': 13.3645, 'grad_norm': 6.5990800857543945, 'learning_rate': 4.99909810829127e-05, 'epoch': 0.0}
{'loss': 12.4055, 'grad_norm': 6.683645248413086, 'learning_rate': 4.999088979832679e-05, 'epoch': 0.0}
                                                                                                                                                 
{'eval_loss': nan, 'eval_runtime': 76.8641, 'eval_samples_per_second': 20.816, 'eval_steps_per_second': 10.408, 'epoch': 0.0}

[WANDB_CALLBACK] Found and logging eval_loss to W&B: nan

{'loss': 29.899, 'grad_norm': 6.525845050811768, 'learning_rate': 4.999079851374089e-05, 'epoch': 0.0}
{'loss': 9.2042, 'grad_norm': 4.931001663208008, 'learning_rate': 4.999070722915499e-05, 'epoch': 0.0}
{'loss': 16.9507, 'grad_norm': 7.041357040405273, 'learning_rate': 4.999061594456908e-05, 'epoch': 0.0}
{'loss': 9.527, 'grad_norm': 6.542028427124023, 'learning_rate': 4.999052465998318e-05, 'epoch': 0.0}
{'loss': 15.0052, 'grad_norm': 6.084825038909912, 'learning_rate': 4.999043337539727e-05, 'epoch': 0.0}
{'loss': 20.0835, 'grad_norm': 4.967844486236572, 'learning_rate': 4.999034209081137e-05, 'epoch': 0.0}
{'loss': 12.6917, 'grad_norm': 6.398556232452393, 'learning_rate': 4.9990250806225466e-05, 'epoch': 0.0}
{'loss': 11.6898, 'grad_norm': 5.9569292068481445, 'learning_rate': 4.9990159521639564e-05, 'epoch': 0.0}
{'loss': 8.1612, 'grad_norm': 8.730210304260254, 'learning_rate': 4.9990068237053656e-05, 'epoch': 0.0}
{'loss': 11.9797, 'grad_norm': 7.138896465301514, 'learning_rate': 4.9989976952467755e-05, 'epoch': 0.0}
{'loss': 13.2235, 'grad_norm': 8.127522468566895, 'learning_rate': 4.9989885667881846e-05, 'epoch': 0.0}
{'loss': 8.8998, 'grad_norm': 6.692785263061523, 'learning_rate': 4.9989794383295945e-05, 'epoch': 0.0}
{'loss': 9.2563, 'grad_norm': 7.3831963539123535, 'learning_rate': 4.9989703098710037e-05, 'epoch': 0.0}
{'loss': 9.8492, 'grad_norm': 5.186776161193848, 'learning_rate': 4.9989611814124135e-05, 'epoch': 0.0}
{'loss': 10.7109, 'grad_norm': 5.906999588012695, 'learning_rate': 4.9989520529538233e-05, 'epoch': 0.0}
{'loss': 13.0711, 'grad_norm': 7.51191520690918, 'learning_rate': 4.998942924495233e-05, 'epoch': 0.0}
{'loss': 10.1611, 'grad_norm': 5.5116729736328125, 'learning_rate': 4.998933796036643e-05, 'epoch': 0.0}
{'loss': 17.1953, 'grad_norm': 7.737943649291992, 'learning_rate': 4.998924667578052e-05, 'epoch': 0.0}
{'loss': 14.5887, 'grad_norm': 5.5816264152526855, 'learning_rate': 4.998915539119462e-05, 'epoch': 0.0}
{'loss': 14.3308, 'grad_norm': 6.206367015838623, 'learning_rate': 4.998906410660871e-05, 'epoch': 0.0}
{'loss': 11.4393, 'grad_norm': 4.505338191986084, 'learning_rate': 4.998897282202281e-05, 'epoch': 0.0}
{'loss': 22.2376, 'grad_norm': 5.659420013427734, 'learning_rate': 4.99888815374369e-05, 'epoch': 0.0}
{'loss': 14.1212, 'grad_norm': 6.62218713760376, 'learning_rate': 4.9988790252851e-05, 'epoch': 0.0}
{'loss': 13.3145, 'grad_norm': 6.3545379638671875, 'learning_rate': 4.99886989682651e-05, 'epoch': 0.0}
{'loss': 10.0034, 'grad_norm': 7.328298568725586, 'learning_rate': 4.99886076836792e-05, 'epoch': 0.0}
{'loss': 12.8704, 'grad_norm': 7.329418182373047, 'learning_rate': 4.998851639909329e-05, 'epoch': 0.0}
{'loss': 10.5725, 'grad_norm': 6.203294277191162, 'learning_rate': 4.998842511450739e-05, 'epoch': 0.0}
{'loss': 9.9899, 'grad_norm': 8.115229606628418, 'learning_rate': 4.9988333829921487e-05, 'epoch': 0.0}
{'loss': 19.1068, 'grad_norm': 8.048980712890625, 'learning_rate': 4.998824254533558e-05, 'epoch': 0.0}
{'loss': 11.9, 'grad_norm': 7.96477746963501, 'learning_rate': 4.998815126074968e-05, 'epoch': 0.0}
{'loss': 13.3556, 'grad_norm': 5.7069597244262695, 'learning_rate': 4.998805997616377e-05, 'epoch': 0.0}
{'loss': 12.535, 'grad_norm': 6.057886600494385, 'learning_rate': 4.998796869157787e-05, 'epoch': 0.0}
{'loss': 18.8293, 'grad_norm': 6.097301006317139, 'learning_rate': 4.9987877406991965e-05, 'epoch': 0.0}
{'loss': 9.8039, 'grad_norm': 6.101832389831543, 'learning_rate': 4.9987786122406064e-05, 'epoch': 0.0}
{'loss': 11.7422, 'grad_norm': 6.077375888824463, 'learning_rate': 4.9987694837820156e-05, 'epoch': 0.0}
{'loss': 15.282, 'grad_norm': 5.914840221405029, 'learning_rate': 4.9987603553234254e-05, 'epoch': 0.0}
{'loss': 10.0717, 'grad_norm': 6.892072677612305, 'learning_rate': 4.9987512268648346e-05, 'epoch': 0.0}
{'loss': 12.1119, 'grad_norm': 6.986256122589111, 'learning_rate': 4.9987420984062444e-05, 'epoch': 0.0}
{'loss': 11.3345, 'grad_norm': 5.66200590133667, 'learning_rate': 4.998732969947654e-05, 'epoch': 0.0}
{'loss': 14.0675, 'grad_norm': 5.250151634216309, 'learning_rate': 4.9987238414890634e-05, 'epoch': 0.0}
{'loss': 9.5921, 'grad_norm': 7.143795490264893, 'learning_rate': 4.998714713030473e-05, 'epoch': 0.0}
{'loss': 14.2908, 'grad_norm': 5.538925647735596, 'learning_rate': 4.9987055845718825e-05, 'epoch': 0.0}
{'loss': 10.5871, 'grad_norm': 7.534239292144775, 'learning_rate': 4.998696456113292e-05, 'epoch': 0.0}
{'loss': 12.6546, 'grad_norm': 7.0358781814575195, 'learning_rate': 4.998687327654702e-05, 'epoch': 0.0}
{'loss': 17.8278, 'grad_norm': 6.9247212409973145, 'learning_rate': 4.998678199196112e-05, 'epoch': 0.0}
{'loss': 10.1458, 'grad_norm': 4.9404683113098145, 'learning_rate': 4.998669070737521e-05, 'epoch': 0.0}
{'loss': 9.1135, 'grad_norm': 4.782868385314941, 'learning_rate': 4.998659942278931e-05, 'epoch': 0.0}
{'loss': 10.4061, 'grad_norm': 7.420772075653076, 'learning_rate': 4.99865081382034e-05, 'epoch': 0.0}
{'loss': 20.0509, 'grad_norm': 6.510130882263184, 'learning_rate': 4.99864168536175e-05, 'epoch': 0.0}
{'loss': 11.6239, 'grad_norm': 6.623476982116699, 'learning_rate': 4.998632556903159e-05, 'epoch': 0.0}
{'loss': 10.3259, 'grad_norm': 7.370986461639404, 'learning_rate': 4.998623428444569e-05, 'epoch': 0.0}
{'loss': 12.5813, 'grad_norm': 6.777688026428223, 'learning_rate': 4.998614299985979e-05, 'epoch': 0.0}
{'loss': 10.1265, 'grad_norm': 6.088871479034424, 'learning_rate': 4.998605171527389e-05, 'epoch': 0.0}
{'loss': 15.6765, 'grad_norm': 6.540444374084473, 'learning_rate': 4.9985960430687986e-05, 'epoch': 0.0}
{'loss': 24.3708, 'grad_norm': 4.427586078643799, 'learning_rate': 4.998586914610208e-05, 'epoch': 0.0}
{'loss': 16.3295, 'grad_norm': 4.928659439086914, 'learning_rate': 4.9985777861516176e-05, 'epoch': 0.0}
{'loss': 15.4664, 'grad_norm': 5.762606620788574, 'learning_rate': 4.998568657693027e-05, 'epoch': 0.0}
{'loss': 11.5006, 'grad_norm': 5.792571544647217, 'learning_rate': 4.9985595292344366e-05, 'epoch': 0.0}
{'loss': 13.8111, 'grad_norm': 6.149251937866211, 'learning_rate': 4.998550400775846e-05, 'epoch': 0.0}
{'loss': 16.1164, 'grad_norm': 4.879128456115723, 'learning_rate': 4.9985412723172556e-05, 'epoch': 0.0}
{'loss': 13.873, 'grad_norm': 6.0903167724609375, 'learning_rate': 4.9985321438586655e-05, 'epoch': 0.0}
{'loss': 12.4041, 'grad_norm': 6.670941352844238, 'learning_rate': 4.998523015400075e-05, 'epoch': 0.0}
{'loss': 16.7872, 'grad_norm': 5.888612270355225, 'learning_rate': 4.9985138869414845e-05, 'epoch': 0.0}
{'loss': 13.6823, 'grad_norm': 6.352848529815674, 'learning_rate': 4.9985047584828944e-05, 'epoch': 0.0}
{'loss': 13.929, 'grad_norm': 7.513725757598877, 'learning_rate': 4.998495630024304e-05, 'epoch': 0.0}
{'loss': 15.6903, 'grad_norm': 7.939059734344482, 'learning_rate': 4.9984865015657134e-05, 'epoch': 0.0}
{'loss': 11.8994, 'grad_norm': 5.788937091827393, 'learning_rate': 4.998477373107123e-05, 'epoch': 0.0}
{'loss': 18.3853, 'grad_norm': 4.785853385925293, 'learning_rate': 4.9984682446485324e-05, 'epoch': 0.0}
{'loss': 11.1989, 'grad_norm': 6.287520885467529, 'learning_rate': 4.998459116189942e-05, 'epoch': 0.0}
{'loss': 10.5821, 'grad_norm': 6.551604747772217, 'learning_rate': 4.998449987731352e-05, 'epoch': 0.0}
{'loss': 14.5721, 'grad_norm': 7.52907657623291, 'learning_rate': 4.998440859272762e-05, 'epoch': 0.0}
{'loss': 11.5741, 'grad_norm': 6.983857154846191, 'learning_rate': 4.998431730814171e-05, 'epoch': 0.0}
{'loss': 10.9819, 'grad_norm': 6.878514289855957, 'learning_rate': 4.998422602355581e-05, 'epoch': 0.0}
{'loss': 31.0775, 'grad_norm': 6.936252593994141, 'learning_rate': 4.99841347389699e-05, 'epoch': 0.0}
{'loss': 13.9839, 'grad_norm': 5.502370357513428, 'learning_rate': 4.9984043454384e-05, 'epoch': 0.0}
{'loss': 10.5417, 'grad_norm': 5.004361152648926, 'learning_rate': 4.998395216979809e-05, 'epoch': 0.0}
{'loss': 13.9387, 'grad_norm': 5.201839447021484, 'learning_rate': 4.998386088521219e-05, 'epoch': 0.0}
{'loss': 14.4268, 'grad_norm': 5.171626091003418, 'learning_rate': 4.998376960062629e-05, 'epoch': 0.0}
{'loss': 10.287, 'grad_norm': 5.539283752441406, 'learning_rate': 4.998367831604038e-05, 'epoch': 0.0}
{'loss': 9.1599, 'grad_norm': 6.3203535079956055, 'learning_rate': 4.9983587031454485e-05, 'epoch': 0.0}
{'loss': 13.9443, 'grad_norm': 6.688493728637695, 'learning_rate': 4.998349574686858e-05, 'epoch': 0.0}
{'loss': 15.5294, 'grad_norm': 6.6673808097839355, 'learning_rate': 4.9983404462282675e-05, 'epoch': 0.0}
{'loss': 9.1231, 'grad_norm': 6.02794075012207, 'learning_rate': 4.998331317769677e-05, 'epoch': 0.0}
{'loss': 10.0654, 'grad_norm': 5.449902534484863, 'learning_rate': 4.9983221893110866e-05, 'epoch': 0.0}
{'loss': 14.262, 'grad_norm': 7.515832424163818, 'learning_rate': 4.998313060852496e-05, 'epoch': 0.0}
{'loss': 10.2117, 'grad_norm': 5.892580986022949, 'learning_rate': 4.9983039323939056e-05, 'epoch': 0.0}
{'loss': 11.0572, 'grad_norm': 5.619451999664307, 'learning_rate': 4.998294803935315e-05, 'epoch': 0.0}
{'loss': 10.9179, 'grad_norm': 5.3999199867248535, 'learning_rate': 4.9982856754767246e-05, 'epoch': 0.0}
{'loss': 10.3615, 'grad_norm': 7.234467506408691, 'learning_rate': 4.9982765470181344e-05, 'epoch': 0.0}
{'loss': 10.9079, 'grad_norm': 7.0467705726623535, 'learning_rate': 4.998267418559544e-05, 'epoch': 0.0}
{'loss': 8.8412, 'grad_norm': 6.498805522918701, 'learning_rate': 4.998258290100954e-05, 'epoch': 0.0}
{'loss': 10.0802, 'grad_norm': 6.536457061767578, 'learning_rate': 4.998249161642363e-05, 'epoch': 0.0}
{'loss': 10.8907, 'grad_norm': 5.041279315948486, 'learning_rate': 4.998240033183773e-05, 'epoch': 0.0}
{'loss': 12.0321, 'grad_norm': 5.500306606292725, 'learning_rate': 4.998230904725182e-05, 'epoch': 0.0}
{'loss': 7.3362, 'grad_norm': 8.18062686920166, 'learning_rate': 4.998221776266592e-05, 'epoch': 0.0}
{'loss': 16.8379, 'grad_norm': 6.383415699005127, 'learning_rate': 4.998212647808001e-05, 'epoch': 0.0}
{'loss': 12.1164, 'grad_norm': 5.075313568115234, 'learning_rate': 4.998203519349411e-05, 'epoch': 0.0}
{'loss': 10.5604, 'grad_norm': 6.772453308105469, 'learning_rate': 4.998194390890821e-05, 'epoch': 0.0}
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\train_model.py", line 48, in main
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\training_utils.py", line 111, in run_training
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 2237, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 2583, in _inner_training_loop
    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
