  0%|                                                                        | 0/200 [00:00<?, ?it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
  1%|▋                                                               | 2/200 [00:01<01:38,  2.00it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 10.4545, 'grad_norm': 27.484081268310547, 'learning_rate': 0.0001, 'epoch': 0.5}
{'loss': 10.1562, 'grad_norm': 17.191335678100586, 'learning_rate': 9.95e-05, 'epoch': 1.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.638367652893066, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5, 'eval_samples_per_second': 32.003, 'eval_steps_per_second': 4.0, 'epoch': 1.0}
  2%|█▎                                                              | 4/200 [00:03<02:39,  1.23it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 10.2356, 'grad_norm': 14.099441528320312, 'learning_rate': 9.900000000000001e-05, 'epoch': 1.5}
{'loss': 10.0742, 'grad_norm': 10.861246109008789, 'learning_rate': 9.850000000000001e-05, 'epoch': 2.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.565103530883789, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4524, 'eval_samples_per_second': 35.364, 'eval_steps_per_second': 4.42, 'epoch': 2.0}
  3%|█▉                                                              | 6/200 [00:06<02:50,  1.14it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 10.3125, 'grad_norm': 12.179686546325684, 'learning_rate': 9.8e-05, 'epoch': 2.5}
{'loss': 9.85, 'grad_norm': 12.707938194274902, 'learning_rate': 9.75e-05, 'epoch': 3.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.196428298950195, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5083, 'eval_samples_per_second': 31.48, 'eval_steps_per_second': 3.935, 'epoch': 3.0}
  4%|██▌                                                             | 8/200 [00:08<02:59,  1.07it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 10.1161, 'grad_norm': 14.970026016235352, 'learning_rate': 9.7e-05, 'epoch': 3.5}
{'loss': 9.5562, 'grad_norm': 9.343781471252441, 'learning_rate': 9.65e-05, 'epoch': 4.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.184896469116211, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4121, 'eval_samples_per_second': 38.827, 'eval_steps_per_second': 4.853, 'epoch': 4.0}
  5%|███▏                                                           | 10/200 [00:10<02:57,  1.07it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 9.066, 'grad_norm': 16.212499618530273, 'learning_rate': 9.6e-05, 'epoch': 4.5}
{'loss': 9.2784, 'grad_norm': 11.209117889404297, 'learning_rate': 9.55e-05, 'epoch': 5.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.346153259277344, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4561, 'eval_samples_per_second': 35.08, 'eval_steps_per_second': 4.385, 'epoch': 5.0}
  6%|███▊                                                           | 12/200 [00:13<02:56,  1.07it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 9.9659, 'grad_norm': 11.253849983215332, 'learning_rate': 9.5e-05, 'epoch': 5.5}
{'loss': 9.0714, 'grad_norm': 13.651962280273438, 'learning_rate': 9.449999999999999e-05, 'epoch': 6.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.442708969116211, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.413, 'eval_samples_per_second': 38.743, 'eval_steps_per_second': 4.843, 'epoch': 6.0}
  7%|████▍                                                          | 14/200 [00:15<02:57,  1.05it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 9.4062, 'grad_norm': 10.098942756652832, 'learning_rate': 9.4e-05, 'epoch': 6.5}
{'loss': 8.0521, 'grad_norm': 11.008966445922852, 'learning_rate': 9.350000000000001e-05, 'epoch': 7.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.078947067260742, 'eval_mlm_accuracy': 0.04, 'eval_runtime': 0.4945, 'eval_samples_per_second': 32.355, 'eval_steps_per_second': 4.044, 'epoch': 7.0}
  8%|█████                                                          | 16/200 [00:17<02:50,  1.08it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 8.987, 'grad_norm': 10.321228981018066, 'learning_rate': 9.300000000000001e-05, 'epoch': 7.5}
{'loss': 8.8385, 'grad_norm': 10.99954605102539, 'learning_rate': 9.250000000000001e-05, 'epoch': 8.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.862197875976562, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.408, 'eval_samples_per_second': 39.212, 'eval_steps_per_second': 4.901, 'epoch': 8.0}
  9%|█████▋                                                         | 18/200 [00:19<02:52,  1.05it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 9.3304, 'grad_norm': 9.329418182373047, 'learning_rate': 9.200000000000001e-05, 'epoch': 8.5}
{'loss': 9.3652, 'grad_norm': 8.948402404785156, 'learning_rate': 9.15e-05, 'epoch': 9.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.21588134765625, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.434, 'eval_samples_per_second': 36.863, 'eval_steps_per_second': 4.608, 'epoch': 9.0}
 10%|██████▎                                                        | 20/200 [00:22<03:09,  1.05s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 8.975, 'grad_norm': 15.779026985168457, 'learning_rate': 9.1e-05, 'epoch': 9.5}
{'loss': 8.2043, 'grad_norm': 10.225428581237793, 'learning_rate': 9.05e-05, 'epoch': 10.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.302343368530273, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5091, 'eval_samples_per_second': 31.425, 'eval_steps_per_second': 3.928, 'epoch': 10.0}
 11%|██████▉                                                        | 22/200 [00:25<03:10,  1.07s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 8.6836, 'grad_norm': 8.704745292663574, 'learning_rate': 9e-05, 'epoch': 10.5}
{'loss': 7.5352, 'grad_norm': 14.491921424865723, 'learning_rate': 8.950000000000001e-05, 'epoch': 11.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.195913314819336, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5353, 'eval_samples_per_second': 29.891, 'eval_steps_per_second': 3.736, 'epoch': 11.0}
 12%|███████▌                                                       | 24/200 [00:27<03:14,  1.11s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 8.4091, 'grad_norm': 11.470622062683105, 'learning_rate': 8.900000000000001e-05, 'epoch': 11.5}
{'loss': 8.0437, 'grad_norm': 10.916495323181152, 'learning_rate': 8.850000000000001e-05, 'epoch': 12.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.987821578979492, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5509, 'eval_samples_per_second': 29.042, 'eval_steps_per_second': 3.63, 'epoch': 12.0}
 13%|████████▏                                                      | 26/200 [00:30<03:18,  1.14s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 8.2094, 'grad_norm': 8.420520782470703, 'learning_rate': 8.800000000000001e-05, 'epoch': 12.5}
{'loss': 8.1786, 'grad_norm': 14.918004035949707, 'learning_rate': 8.75e-05, 'epoch': 13.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.059588432312012, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.525, 'eval_samples_per_second': 30.477, 'eval_steps_per_second': 3.81, 'epoch': 13.0}
 14%|████████▊                                                      | 28/200 [00:32<03:04,  1.07s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.8313, 'grad_norm': 9.250471115112305, 'learning_rate': 8.7e-05, 'epoch': 13.5}
{'loss': 7.6466, 'grad_norm': 9.444290161132812, 'learning_rate': 8.65e-05, 'epoch': 14.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.651041030883789, 'eval_mlm_accuracy': 0.038461538461538464, 'eval_runtime': 0.4351, 'eval_samples_per_second': 36.771, 'eval_steps_per_second': 4.596, 'epoch': 14.0}
 15%|█████████▍                                                     | 30/200 [00:35<02:52,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.5352, 'grad_norm': 9.704194068908691, 'learning_rate': 8.6e-05, 'epoch': 14.5}
{'loss': 8.1035, 'grad_norm': 8.504085540771484, 'learning_rate': 8.55e-05, 'epoch': 15.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.879035949707031, 'eval_mlm_accuracy': 0.029411764705882353, 'eval_runtime': 0.3977, 'eval_samples_per_second': 40.236, 'eval_steps_per_second': 5.03, 'epoch': 15.0}
 16%|██████████                                                     | 32/200 [00:37<02:44,  1.02it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.9085, 'grad_norm': 9.12906265258789, 'learning_rate': 8.5e-05, 'epoch': 15.5}
{'loss': 7.9625, 'grad_norm': 11.03193473815918, 'learning_rate': 8.450000000000001e-05, 'epoch': 16.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.734903335571289, 'eval_mlm_accuracy': 0.038461538461538464, 'eval_runtime': 0.502, 'eval_samples_per_second': 31.872, 'eval_steps_per_second': 3.984, 'epoch': 16.0}
 17%|██████████▋                                                    | 34/200 [00:39<02:49,  1.02s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.2886, 'grad_norm': 8.83552360534668, 'learning_rate': 8.4e-05, 'epoch': 16.5}
{'loss': 7.3802, 'grad_norm': 11.025151252746582, 'learning_rate': 8.35e-05, 'epoch': 17.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.985788345336914, 'eval_mlm_accuracy': 0.045454545454545456, 'eval_runtime': 0.4222, 'eval_samples_per_second': 37.893, 'eval_steps_per_second': 4.737, 'epoch': 17.0}
 18%|███████████▎                                                   | 36/200 [00:42<02:40,  1.02it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.0573, 'grad_norm': 10.563400268554688, 'learning_rate': 8.3e-05, 'epoch': 17.5}
{'loss': 7.7422, 'grad_norm': 9.903203010559082, 'learning_rate': 8.25e-05, 'epoch': 18.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.16469955444336, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4277, 'eval_samples_per_second': 37.409, 'eval_steps_per_second': 4.676, 'epoch': 18.0}
 19%|███████████▉                                                   | 38/200 [00:44<02:33,  1.05it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.5576, 'grad_norm': 7.469976425170898, 'learning_rate': 8.2e-05, 'epoch': 18.5}
{'loss': 6.684, 'grad_norm': 12.245420455932617, 'learning_rate': 8.15e-05, 'epoch': 19.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.521535873413086, 'eval_mlm_accuracy': 0.037037037037037035, 'eval_runtime': 0.4891, 'eval_samples_per_second': 32.711, 'eval_steps_per_second': 4.089, 'epoch': 19.0}
 20%|████████████▌                                                  | 40/200 [00:46<02:37,  1.02it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.8359, 'grad_norm': 10.277494430541992, 'learning_rate': 8.1e-05, 'epoch': 19.5}
{'loss': 7.5781, 'grad_norm': 10.303596496582031, 'learning_rate': 8.05e-05, 'epoch': 20.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.8857421875, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4859, 'eval_samples_per_second': 32.927, 'eval_steps_per_second': 4.116, 'epoch': 20.0}
 21%|█████████████▏                                                 | 42/200 [00:48<02:31,  1.04it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.6927, 'grad_norm': 13.626280784606934, 'learning_rate': 8e-05, 'epoch': 20.5}
{'loss': 6.582, 'grad_norm': 9.981949806213379, 'learning_rate': 7.950000000000001e-05, 'epoch': 21.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.971755027770996, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4728, 'eval_samples_per_second': 33.842, 'eval_steps_per_second': 4.23, 'epoch': 21.0}
 22%|█████████████▊                                                 | 44/200 [00:51<02:33,  1.02it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.151, 'grad_norm': 7.902513027191162, 'learning_rate': 7.900000000000001e-05, 'epoch': 21.5}
{'loss': 6.7674, 'grad_norm': 12.76854133605957, 'learning_rate': 7.850000000000001e-05, 'epoch': 22.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.743772506713867, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4012, 'eval_samples_per_second': 39.878, 'eval_steps_per_second': 4.985, 'epoch': 22.0}
 23%|██████████████▍                                                | 46/200 [00:53<02:25,  1.06it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.0966, 'grad_norm': 10.338747024536133, 'learning_rate': 7.800000000000001e-05, 'epoch': 22.5}
{'loss': 7.4396, 'grad_norm': 10.024188041687012, 'learning_rate': 7.75e-05, 'epoch': 23.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.322368621826172, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4282, 'eval_samples_per_second': 37.367, 'eval_steps_per_second': 4.671, 'epoch': 23.0}
 24%|███████████████                                                | 48/200 [00:55<02:32,  1.00s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.2734, 'grad_norm': 22.8973388671875, 'learning_rate': 7.7e-05, 'epoch': 23.5}
{'loss': 6.8099, 'grad_norm': 8.327019691467285, 'learning_rate': 7.65e-05, 'epoch': 24.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.751823425292969, 'eval_mlm_accuracy': 0.047619047619047616, 'eval_runtime': 0.4098, 'eval_samples_per_second': 39.045, 'eval_steps_per_second': 4.881, 'epoch': 24.0}
 25%|███████████████▊                                               | 50/200 [00:58<02:29,  1.00it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.9651, 'grad_norm': 8.41203498840332, 'learning_rate': 7.6e-05, 'epoch': 24.5}
{'loss': 6.8115, 'grad_norm': 9.092511177062988, 'learning_rate': 7.55e-05, 'epoch': 25.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.88671875, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4712, 'eval_samples_per_second': 33.956, 'eval_steps_per_second': 4.244, 'epoch': 25.0}
 26%|████████████████▍                                              | 52/200 [01:00<02:33,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.8196, 'grad_norm': 10.082351684570312, 'learning_rate': 7.500000000000001e-05, 'epoch': 25.5}
{'loss': 6.6763, 'grad_norm': 9.109182357788086, 'learning_rate': 7.450000000000001e-05, 'epoch': 26.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.704038619995117, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4785, 'eval_samples_per_second': 33.434, 'eval_steps_per_second': 4.179, 'epoch': 26.0}
 27%|█████████████████                                              | 54/200 [01:03<02:24,  1.01it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.7055, 'grad_norm': 9.172856330871582, 'learning_rate': 7.4e-05, 'epoch': 26.5}
{'loss': 6.6363, 'grad_norm': 7.93241024017334, 'learning_rate': 7.35e-05, 'epoch': 27.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.633203506469727, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4341, 'eval_samples_per_second': 36.857, 'eval_steps_per_second': 4.607, 'epoch': 27.0}
 28%|█████████████████▋                                             | 56/200 [01:05<02:25,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.519, 'grad_norm': 9.493215560913086, 'learning_rate': 7.3e-05, 'epoch': 27.5}
{'loss': 7.0021, 'grad_norm': 9.35858154296875, 'learning_rate': 7.25e-05, 'epoch': 28.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.1171875, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4455, 'eval_samples_per_second': 35.917, 'eval_steps_per_second': 4.49, 'epoch': 28.0}
 29%|██████████████████▎                                            | 58/200 [01:07<02:27,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.6438, 'grad_norm': 15.434989929199219, 'learning_rate': 7.2e-05, 'epoch': 28.5}
{'loss': 6.0772, 'grad_norm': 8.627144813537598, 'learning_rate': 7.15e-05, 'epoch': 29.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.406307220458984, 'eval_mlm_accuracy': 0.04, 'eval_runtime': 0.4275, 'eval_samples_per_second': 37.43, 'eval_steps_per_second': 4.679, 'epoch': 29.0}
 30%|██████████████████▉                                            | 60/200 [01:10<02:20,  1.00s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.1221, 'grad_norm': 8.343469619750977, 'learning_rate': 7.1e-05, 'epoch': 29.5}
{'loss': 6.321, 'grad_norm': 9.91598892211914, 'learning_rate': 7.05e-05, 'epoch': 30.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.546224594116211, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4618, 'eval_samples_per_second': 34.648, 'eval_steps_per_second': 4.331, 'epoch': 30.0}
 31%|███████████████████▌                                           | 62/200 [01:12<02:17,  1.01it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.4423, 'grad_norm': 9.171551704406738, 'learning_rate': 7e-05, 'epoch': 30.5}
{'loss': 6.7969, 'grad_norm': 17.19993782043457, 'learning_rate': 6.95e-05, 'epoch': 31.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.391368865966797, 'eval_mlm_accuracy': 0.038461538461538464, 'eval_runtime': 0.4935, 'eval_samples_per_second': 32.424, 'eval_steps_per_second': 4.053, 'epoch': 31.0}
 32%|████████████████████▏                                          | 64/200 [01:15<02:20,  1.03s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.2729, 'grad_norm': 8.424077033996582, 'learning_rate': 6.9e-05, 'epoch': 31.5}
{'loss': 6.2656, 'grad_norm': 16.696760177612305, 'learning_rate': 6.850000000000001e-05, 'epoch': 32.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.395312309265137, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.499, 'eval_samples_per_second': 32.063, 'eval_steps_per_second': 4.008, 'epoch': 32.0}
 33%|████████████████████▊                                          | 66/200 [01:17<02:23,  1.07s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.4635, 'grad_norm': 19.25536346435547, 'learning_rate': 6.800000000000001e-05, 'epoch': 32.5}
{'loss': 5.5588, 'grad_norm': 7.714524269104004, 'learning_rate': 6.750000000000001e-05, 'epoch': 33.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.75900650024414, 'eval_mlm_accuracy': 0.04, 'eval_runtime': 0.4276, 'eval_samples_per_second': 37.421, 'eval_steps_per_second': 4.678, 'epoch': 33.0}
 34%|█████████████████████▍                                         | 68/200 [01:20<02:18,  1.05s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.423, 'grad_norm': 9.37047290802002, 'learning_rate': 6.7e-05, 'epoch': 33.5}
{'loss': 5.8767, 'grad_norm': 11.927417755126953, 'learning_rate': 6.65e-05, 'epoch': 34.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.49045181274414, 'eval_mlm_accuracy': 0.06666666666666667, 'eval_runtime': 0.4287, 'eval_samples_per_second': 37.325, 'eval_steps_per_second': 4.666, 'epoch': 34.0}
 35%|██████████████████████                                         | 70/200 [01:22<02:11,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.6, 'grad_norm': 10.788178443908691, 'learning_rate': 6.6e-05, 'epoch': 34.5}
{'loss': 5.2812, 'grad_norm': 10.599836349487305, 'learning_rate': 6.55e-05, 'epoch': 35.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.9375, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5016, 'eval_samples_per_second': 31.896, 'eval_steps_per_second': 3.987, 'epoch': 35.0}
 36%|██████████████████████▋                                        | 72/200 [01:24<02:08,  1.00s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.6458, 'grad_norm': 10.016372680664062, 'learning_rate': 6.500000000000001e-05, 'epoch': 35.5}
{'loss': 5.3371, 'grad_norm': 12.304819107055664, 'learning_rate': 6.450000000000001e-05, 'epoch': 36.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.421441078186035, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4746, 'eval_samples_per_second': 33.712, 'eval_steps_per_second': 4.214, 'epoch': 36.0}
 37%|███████████████████████▎                                       | 74/200 [01:27<02:03,  1.02it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.3097, 'grad_norm': 10.334869384765625, 'learning_rate': 6.400000000000001e-05, 'epoch': 36.5}
{'loss': 6.9156, 'grad_norm': 10.868287086486816, 'learning_rate': 6.35e-05, 'epoch': 37.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.048295974731445, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5143, 'eval_samples_per_second': 31.113, 'eval_steps_per_second': 3.889, 'epoch': 37.0}
 38%|███████████████████████▉                                       | 76/200 [01:29<02:08,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.075, 'grad_norm': 10.474844932556152, 'learning_rate': 6.3e-05, 'epoch': 37.5}
{'loss': 4.8237, 'grad_norm': 11.627152442932129, 'learning_rate': 6.25e-05, 'epoch': 38.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.564630508422852, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4176, 'eval_samples_per_second': 38.316, 'eval_steps_per_second': 4.789, 'epoch': 38.0}
 39%|████████████████████████▌                                      | 78/200 [01:32<02:12,  1.09s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.1391, 'grad_norm': 10.486491203308105, 'learning_rate': 6.2e-05, 'epoch': 38.5}
{'loss': 5.3141, 'grad_norm': 10.488938331604004, 'learning_rate': 6.15e-05, 'epoch': 39.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.831853866577148, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5449, 'eval_samples_per_second': 29.366, 'eval_steps_per_second': 3.671, 'epoch': 39.0}
 40%|█████████████████████████▏                                     | 80/200 [01:35<02:12,  1.11s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.5022, 'grad_norm': 13.83455753326416, 'learning_rate': 6.1e-05, 'epoch': 39.5}
{'loss': 5.9453, 'grad_norm': 9.130698204040527, 'learning_rate': 6.05e-05, 'epoch': 40.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.486738204956055, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5156, 'eval_samples_per_second': 31.033, 'eval_steps_per_second': 3.879, 'epoch': 40.0}
 41%|█████████████████████████▊                                     | 82/200 [01:37<02:14,  1.14s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.5729, 'grad_norm': 8.991153717041016, 'learning_rate': 6e-05, 'epoch': 40.5}
{'loss': 5.1312, 'grad_norm': 10.923208236694336, 'learning_rate': 5.95e-05, 'epoch': 41.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.313615798950195, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5033, 'eval_samples_per_second': 31.791, 'eval_steps_per_second': 3.974, 'epoch': 41.0}
 42%|██████████████████████████▍                                    | 84/200 [01:40<02:10,  1.13s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.6523, 'grad_norm': 12.572966575622559, 'learning_rate': 5.9e-05, 'epoch': 41.5}
{'loss': 5.6367, 'grad_norm': 7.8774261474609375, 'learning_rate': 5.85e-05, 'epoch': 42.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.809027671813965, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4613, 'eval_samples_per_second': 34.683, 'eval_steps_per_second': 4.335, 'epoch': 42.0}
 43%|███████████████████████████                                    | 86/200 [01:43<02:02,  1.08s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.4863, 'grad_norm': 12.744208335876465, 'learning_rate': 5.8e-05, 'epoch': 42.5}
{'loss': 5.7937, 'grad_norm': 10.40782642364502, 'learning_rate': 5.7499999999999995e-05, 'epoch': 43.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.505273818969727, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5035, 'eval_samples_per_second': 31.78, 'eval_steps_per_second': 3.973, 'epoch': 43.0}
 44%|███████████████████████████▋                                   | 88/200 [01:45<02:02,  1.09s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.5208, 'grad_norm': 11.061358451843262, 'learning_rate': 5.6999999999999996e-05, 'epoch': 43.5}
{'loss': 5.3958, 'grad_norm': 7.164526462554932, 'learning_rate': 5.65e-05, 'epoch': 44.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.453682899475098, 'eval_mlm_accuracy': 0.038461538461538464, 'eval_runtime': 0.5339, 'eval_samples_per_second': 29.968, 'eval_steps_per_second': 3.746, 'epoch': 44.0}
 45%|████████████████████████████▎                                  | 90/200 [01:48<02:03,  1.12s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.821, 'grad_norm': 9.806796073913574, 'learning_rate': 5.6000000000000006e-05, 'epoch': 44.5}
{'loss': 5.3063, 'grad_norm': 10.66795539855957, 'learning_rate': 5.550000000000001e-05, 'epoch': 45.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.82421875, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4528, 'eval_samples_per_second': 35.332, 'eval_steps_per_second': 4.417, 'epoch': 45.0}
 46%|████████████████████████████▉                                  | 92/200 [01:50<01:52,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.5022, 'grad_norm': 8.347556114196777, 'learning_rate': 5.500000000000001e-05, 'epoch': 45.5}
{'loss': 4.9861, 'grad_norm': 11.083391189575195, 'learning_rate': 5.45e-05, 'epoch': 46.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.4853515625, 'eval_mlm_accuracy': 0.041666666666666664, 'eval_runtime': 0.5135, 'eval_samples_per_second': 31.159, 'eval_steps_per_second': 3.895, 'epoch': 46.0}
 47%|█████████████████████████████▌                                 | 94/200 [01:53<01:57,  1.11s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3582, 'grad_norm': 9.253093719482422, 'learning_rate': 5.4000000000000005e-05, 'epoch': 46.5}
{'loss': 5.559, 'grad_norm': 11.002957344055176, 'learning_rate': 5.3500000000000006e-05, 'epoch': 47.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.08263874053955, 'eval_mlm_accuracy': 0.043478260869565216, 'eval_runtime': 0.4928, 'eval_samples_per_second': 32.466, 'eval_steps_per_second': 4.058, 'epoch': 47.0}
 48%|██████████████████████████████▏                                | 96/200 [01:55<01:52,  1.08s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.671, 'grad_norm': 8.161205291748047, 'learning_rate': 5.300000000000001e-05, 'epoch': 47.5}
{'loss': 5.418, 'grad_norm': 11.293277740478516, 'learning_rate': 5.25e-05, 'epoch': 48.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.610441207885742, 'eval_mlm_accuracy': 0.030303030303030304, 'eval_runtime': 0.4157, 'eval_samples_per_second': 38.494, 'eval_steps_per_second': 4.812, 'epoch': 48.0}
 49%|██████████████████████████████▊                                | 98/200 [01:58<01:42,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.333, 'grad_norm': 8.066545486450195, 'learning_rate': 5.2000000000000004e-05, 'epoch': 48.5}
{'loss': 5.8698, 'grad_norm': 9.357095718383789, 'learning_rate': 5.1500000000000005e-05, 'epoch': 49.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.893562316894531, 'eval_mlm_accuracy': 0.038461538461538464, 'eval_runtime': 0.477, 'eval_samples_per_second': 33.544, 'eval_steps_per_second': 4.193, 'epoch': 49.0}
 50%|███████████████████████████████                               | 100/200 [02:00<01:48,  1.09s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.2254, 'grad_norm': 12.33076286315918, 'learning_rate': 5.1000000000000006e-05, 'epoch': 49.5}
{'loss': 5.276, 'grad_norm': 9.255520820617676, 'learning_rate': 5.05e-05, 'epoch': 50.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 8.531959533691406, 'eval_mlm_accuracy': 0.07407407407407407, 'eval_runtime': 0.4382, 'eval_samples_per_second': 36.509, 'eval_steps_per_second': 4.564, 'epoch': 50.0}
 51%|███████████████████████████████▌                              | 102/200 [02:03<01:41,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.7051, 'grad_norm': 11.570566177368164, 'learning_rate': 5e-05, 'epoch': 50.5}
{'loss': 5.4277, 'grad_norm': 8.023417472839355, 'learning_rate': 4.9500000000000004e-05, 'epoch': 51.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.086458206176758, 'eval_mlm_accuracy': 0.043478260869565216, 'eval_runtime': 0.4221, 'eval_samples_per_second': 37.908, 'eval_steps_per_second': 4.739, 'epoch': 51.0}
 52%|████████████████████████████████▏                             | 104/200 [02:05<01:36,  1.00s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.981, 'grad_norm': 8.621772766113281, 'learning_rate': 4.9e-05, 'epoch': 51.5}
{'loss': 5.4688, 'grad_norm': 12.0364990234375, 'learning_rate': 4.85e-05, 'epoch': 52.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.012866973876953, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5026, 'eval_samples_per_second': 31.835, 'eval_steps_per_second': 3.979, 'epoch': 52.0}
 53%|████████████████████████████████▊                             | 106/200 [02:08<01:33,  1.00it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3317, 'grad_norm': 9.284111976623535, 'learning_rate': 4.8e-05, 'epoch': 52.5}
{'loss': 5.1186, 'grad_norm': 8.452628135681152, 'learning_rate': 4.75e-05, 'epoch': 53.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.890462875366211, 'eval_mlm_accuracy': 0.045454545454545456, 'eval_runtime': 0.4753, 'eval_samples_per_second': 33.666, 'eval_steps_per_second': 4.208, 'epoch': 53.0}
 54%|█████████████████████████████████▍                            | 108/200 [02:10<01:38,  1.07s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.293, 'grad_norm': 10.932836532592773, 'learning_rate': 4.7e-05, 'epoch': 53.5}
{'loss': 5.0938, 'grad_norm': 8.995408058166504, 'learning_rate': 4.6500000000000005e-05, 'epoch': 54.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.622596740722656, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5251, 'eval_samples_per_second': 30.472, 'eval_steps_per_second': 3.809, 'epoch': 54.0}
 55%|██████████████████████████████████                            | 110/200 [02:12<01:33,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3229, 'grad_norm': 9.11046314239502, 'learning_rate': 4.600000000000001e-05, 'epoch': 54.5}
{'loss': 5.2143, 'grad_norm': 8.30731201171875, 'learning_rate': 4.55e-05, 'epoch': 55.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.061079025268555, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5266, 'eval_samples_per_second': 30.385, 'eval_steps_per_second': 3.798, 'epoch': 55.0}
 56%|██████████████████████████████████▋                           | 112/200 [02:15<01:33,  1.07s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.5125, 'grad_norm': 14.972397804260254, 'learning_rate': 4.5e-05, 'epoch': 55.5}
{'loss': 5.0768, 'grad_norm': 10.318544387817383, 'learning_rate': 4.4500000000000004e-05, 'epoch': 56.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.014939308166504, 'eval_mlm_accuracy': 0.04, 'eval_runtime': 0.5719, 'eval_samples_per_second': 27.975, 'eval_steps_per_second': 3.497, 'epoch': 56.0}
 57%|███████████████████████████████████▎                          | 114/200 [02:18<01:36,  1.12s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.099, 'grad_norm': 12.7807035446167, 'learning_rate': 4.4000000000000006e-05, 'epoch': 56.5}
{'loss': 5.4034, 'grad_norm': 6.488150119781494, 'learning_rate': 4.35e-05, 'epoch': 57.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.080154418945312, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.443, 'eval_samples_per_second': 36.118, 'eval_steps_per_second': 4.515, 'epoch': 57.0}
 58%|███████████████████████████████████▉                          | 116/200 [02:20<01:32,  1.10s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.6387, 'grad_norm': 7.88749885559082, 'learning_rate': 4.3e-05, 'epoch': 57.5}
{'loss': 4.665, 'grad_norm': 8.419792175292969, 'learning_rate': 4.25e-05, 'epoch': 58.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.63368034362793, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4949, 'eval_samples_per_second': 32.327, 'eval_steps_per_second': 4.041, 'epoch': 58.0}
 59%|████████████████████████████████████▌                         | 118/200 [02:23<01:30,  1.10s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 15.1442, 'grad_norm': 20.817981719970703, 'learning_rate': 4.2e-05, 'epoch': 58.5}
{'loss': 5.4336, 'grad_norm': 9.501309394836426, 'learning_rate': 4.15e-05, 'epoch': 59.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.184255599975586, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5074, 'eval_samples_per_second': 31.533, 'eval_steps_per_second': 3.942, 'epoch': 59.0}
 60%|█████████████████████████████████████▏                        | 120/200 [02:25<01:27,  1.10s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.4303, 'grad_norm': 9.089686393737793, 'learning_rate': 4.1e-05, 'epoch': 59.5}
{'loss': 5.2057, 'grad_norm': 12.841471672058105, 'learning_rate': 4.05e-05, 'epoch': 60.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.910094261169434, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4196, 'eval_samples_per_second': 38.13, 'eval_steps_per_second': 4.766, 'epoch': 60.0}
 61%|█████████████████████████████████████▊                        | 122/200 [02:28<01:18,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.5469, 'grad_norm': 9.097334861755371, 'learning_rate': 4e-05, 'epoch': 60.5}
{'loss': 5.1832, 'grad_norm': 7.533401012420654, 'learning_rate': 3.9500000000000005e-05, 'epoch': 61.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.2109375, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4467, 'eval_samples_per_second': 35.816, 'eval_steps_per_second': 4.477, 'epoch': 61.0}
 62%|██████████████████████████████████████▍                       | 124/200 [02:31<01:24,  1.11s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.6161, 'grad_norm': 8.886038780212402, 'learning_rate': 3.9000000000000006e-05, 'epoch': 61.5}
{'loss': 5.3984, 'grad_norm': 13.062710762023926, 'learning_rate': 3.85e-05, 'epoch': 62.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.050963401794434, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5358, 'eval_samples_per_second': 29.863, 'eval_steps_per_second': 3.733, 'epoch': 62.0}
 63%|███████████████████████████████████████                       | 126/200 [02:33<01:24,  1.15s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.2547, 'grad_norm': 11.215347290039062, 'learning_rate': 3.8e-05, 'epoch': 62.5}
{'loss': 5.4688, 'grad_norm': 11.643742561340332, 'learning_rate': 3.7500000000000003e-05, 'epoch': 63.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.83376693725586, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4487, 'eval_samples_per_second': 35.66, 'eval_steps_per_second': 4.457, 'epoch': 63.0}
 64%|███████████████████████████████████████▋                      | 128/200 [02:36<01:15,  1.05s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.2798, 'grad_norm': 6.784006118774414, 'learning_rate': 3.7e-05, 'epoch': 63.5}
{'loss': 5.6562, 'grad_norm': 15.025577545166016, 'learning_rate': 3.65e-05, 'epoch': 64.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.607812881469727, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4275, 'eval_samples_per_second': 37.426, 'eval_steps_per_second': 4.678, 'epoch': 64.0}
 65%|████████████████████████████████████████▎                     | 130/200 [02:38<01:08,  1.03it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3562, 'grad_norm': 10.113432884216309, 'learning_rate': 3.6e-05, 'epoch': 64.5}
{'loss': 5.0946, 'grad_norm': 7.691590309143066, 'learning_rate': 3.55e-05, 'epoch': 65.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.940505027770996, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4157, 'eval_samples_per_second': 38.489, 'eval_steps_per_second': 4.811, 'epoch': 65.0}
 66%|████████████████████████████████████████▉                     | 132/200 [02:40<01:08,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.332, 'grad_norm': 11.917340278625488, 'learning_rate': 3.5e-05, 'epoch': 65.5}
{'loss': 5.0869, 'grad_norm': 7.509239196777344, 'learning_rate': 3.45e-05, 'epoch': 66.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.227865219116211, 'eval_mlm_accuracy': 0.07407407407407407, 'eval_runtime': 0.4857, 'eval_samples_per_second': 32.945, 'eval_steps_per_second': 4.118, 'epoch': 66.0}
 67%|█████████████████████████████████████████▌                    | 134/200 [02:43<01:06,  1.00s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1766, 'grad_norm': 10.27699089050293, 'learning_rate': 3.4000000000000007e-05, 'epoch': 66.5}
{'loss': 4.5517, 'grad_norm': 8.994756698608398, 'learning_rate': 3.35e-05, 'epoch': 67.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.65990924835205, 'eval_mlm_accuracy': 0.034482758620689655, 'eval_runtime': 0.4381, 'eval_samples_per_second': 36.517, 'eval_steps_per_second': 4.565, 'epoch': 67.0}
 68%|██████████████████████████████████████████▏                   | 136/200 [02:45<01:00,  1.06it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.0781, 'grad_norm': 7.471702575683594, 'learning_rate': 3.3e-05, 'epoch': 67.5}
{'loss': 5.7734, 'grad_norm': 11.876051902770996, 'learning_rate': 3.2500000000000004e-05, 'epoch': 68.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.710379600524902, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4932, 'eval_samples_per_second': 32.44, 'eval_steps_per_second': 4.055, 'epoch': 68.0}
 69%|██████████████████████████████████████████▊                   | 138/200 [02:47<01:02,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.2196, 'grad_norm': 7.115401744842529, 'learning_rate': 3.2000000000000005e-05, 'epoch': 68.5}
{'loss': 4.9388, 'grad_norm': 9.308842658996582, 'learning_rate': 3.15e-05, 'epoch': 69.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.91856575012207, 'eval_mlm_accuracy': 0.045454545454545456, 'eval_runtime': 0.4955, 'eval_samples_per_second': 32.29, 'eval_steps_per_second': 4.036, 'epoch': 69.0}
 70%|███████████████████████████████████████████▍                  | 140/200 [02:50<01:00,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3292, 'grad_norm': 8.52134895324707, 'learning_rate': 3.1e-05, 'epoch': 69.5}
{'loss': 4.877, 'grad_norm': 11.218159675598145, 'learning_rate': 3.05e-05, 'epoch': 70.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.378255844116211, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.435, 'eval_samples_per_second': 36.785, 'eval_steps_per_second': 4.598, 'epoch': 70.0}
 71%|████████████████████████████████████████████                  | 142/200 [02:52<00:56,  1.02it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.7457, 'grad_norm': 9.61568546295166, 'learning_rate': 3e-05, 'epoch': 70.5}
{'loss': 5.2589, 'grad_norm': 12.133134841918945, 'learning_rate': 2.95e-05, 'epoch': 71.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.388671875, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5452, 'eval_samples_per_second': 29.345, 'eval_steps_per_second': 3.668, 'epoch': 71.0}
 72%|████████████████████████████████████████████▋                 | 144/200 [02:55<01:02,  1.12s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1143, 'grad_norm': 7.822035312652588, 'learning_rate': 2.9e-05, 'epoch': 71.5}
{'loss': 5.0901, 'grad_norm': 8.357488632202148, 'learning_rate': 2.8499999999999998e-05, 'epoch': 72.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.164196014404297, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4333, 'eval_samples_per_second': 36.929, 'eval_steps_per_second': 4.616, 'epoch': 72.0}
 73%|█████████████████████████████████████████████▎                | 146/200 [02:57<00:55,  1.03s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.9857, 'grad_norm': 9.032673835754395, 'learning_rate': 2.8000000000000003e-05, 'epoch': 72.5}
{'loss': 5.263, 'grad_norm': 13.19037914276123, 'learning_rate': 2.7500000000000004e-05, 'epoch': 73.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.270537376403809, 'eval_mlm_accuracy': 0.029411764705882353, 'eval_runtime': 0.5707, 'eval_samples_per_second': 28.033, 'eval_steps_per_second': 3.504, 'epoch': 73.0}
 74%|█████████████████████████████████████████████▉                | 148/200 [03:00<00:58,  1.12s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1406, 'grad_norm': 8.572672843933105, 'learning_rate': 2.7000000000000002e-05, 'epoch': 73.5}
{'loss': 4.9245, 'grad_norm': 8.75417709350586, 'learning_rate': 2.6500000000000004e-05, 'epoch': 74.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 8.742897033691406, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4569, 'eval_samples_per_second': 35.019, 'eval_steps_per_second': 4.377, 'epoch': 74.0}
 75%|██████████████████████████████████████████████▌               | 150/200 [03:02<00:51,  1.03s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.0327, 'grad_norm': 6.564064025878906, 'learning_rate': 2.6000000000000002e-05, 'epoch': 74.5}
{'loss': 4.9453, 'grad_norm': 11.544332504272461, 'learning_rate': 2.5500000000000003e-05, 'epoch': 75.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.732954025268555, 'eval_mlm_accuracy': 0.06666666666666667, 'eval_runtime': 0.4939, 'eval_samples_per_second': 32.393, 'eval_steps_per_second': 4.049, 'epoch': 75.0}
 76%|███████████████████████████████████████████████               | 152/200 [03:05<00:50,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.1523, 'grad_norm': 15.094610214233398, 'learning_rate': 2.5e-05, 'epoch': 75.5}
{'loss': 4.7031, 'grad_norm': 9.6771821975708, 'learning_rate': 2.45e-05, 'epoch': 76.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.023784637451172, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5209, 'eval_samples_per_second': 30.717, 'eval_steps_per_second': 3.84, 'epoch': 76.0}
 77%|███████████████████████████████████████████████▋              | 154/200 [03:07<00:47,  1.03s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.7835, 'grad_norm': 8.657694816589355, 'learning_rate': 2.4e-05, 'epoch': 76.5}
{'loss': 5.4099, 'grad_norm': 8.412092208862305, 'learning_rate': 2.35e-05, 'epoch': 77.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.238895416259766, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5238, 'eval_samples_per_second': 30.546, 'eval_steps_per_second': 3.818, 'epoch': 77.0}
 78%|████████████████████████████████████████████████▎             | 156/200 [03:09<00:45,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.8594, 'grad_norm': 9.708622932434082, 'learning_rate': 2.3000000000000003e-05, 'epoch': 77.5}
{'loss': 4.7917, 'grad_norm': 10.298402786254883, 'learning_rate': 2.25e-05, 'epoch': 78.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.941152572631836, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4444, 'eval_samples_per_second': 36.003, 'eval_steps_per_second': 4.5, 'epoch': 78.0}
 79%|████████████████████████████████████████████████▉             | 158/200 [03:12<00:43,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.0295, 'grad_norm': 7.672738075256348, 'learning_rate': 2.2000000000000003e-05, 'epoch': 78.5}
{'loss': 4.4645, 'grad_norm': 10.242767333984375, 'learning_rate': 2.15e-05, 'epoch': 79.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.475615501403809, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4934, 'eval_samples_per_second': 32.43, 'eval_steps_per_second': 4.054, 'epoch': 79.0}
 80%|█████████████████████████████████████████████████▌            | 160/200 [03:15<00:41,  1.05s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.6753, 'grad_norm': 10.972578048706055, 'learning_rate': 2.1e-05, 'epoch': 79.5}
{'loss': 5.0279, 'grad_norm': 8.337573051452637, 'learning_rate': 2.05e-05, 'epoch': 80.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.21397590637207, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5198, 'eval_samples_per_second': 30.783, 'eval_steps_per_second': 3.848, 'epoch': 80.0}
 81%|██████████████████████████████████████████████████▏           | 162/200 [03:17<00:38,  1.02s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1142, 'grad_norm': 8.392563819885254, 'learning_rate': 2e-05, 'epoch': 80.5}
{'loss': 4.7368, 'grad_norm': 9.1871337890625, 'learning_rate': 1.9500000000000003e-05, 'epoch': 81.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.485017776489258, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5047, 'eval_samples_per_second': 31.7, 'eval_steps_per_second': 3.962, 'epoch': 81.0}
 82%|██████████████████████████████████████████████████▊           | 164/200 [03:20<00:39,  1.11s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.8891, 'grad_norm': 9.990148544311523, 'learning_rate': 1.9e-05, 'epoch': 81.5}
{'loss': 5.2476, 'grad_norm': 9.223384857177734, 'learning_rate': 1.85e-05, 'epoch': 82.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.596909523010254, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.523, 'eval_samples_per_second': 30.592, 'eval_steps_per_second': 3.824, 'epoch': 82.0}
 83%|███████████████████████████████████████████████████▍          | 166/200 [03:22<00:36,  1.06s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.0104, 'grad_norm': 7.776395797729492, 'learning_rate': 1.8e-05, 'epoch': 82.5}
{'loss': 5.1271, 'grad_norm': 6.985657691955566, 'learning_rate': 1.75e-05, 'epoch': 83.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.399616241455078, 'eval_mlm_accuracy': 0.04, 'eval_runtime': 0.4409, 'eval_samples_per_second': 36.286, 'eval_steps_per_second': 4.536, 'epoch': 83.0}
 84%|████████████████████████████████████████████████████          | 168/200 [03:24<00:31,  1.02it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.179, 'grad_norm': 9.794432640075684, 'learning_rate': 1.7000000000000003e-05, 'epoch': 83.5}
{'loss': 5.2656, 'grad_norm': 10.326133728027344, 'learning_rate': 1.65e-05, 'epoch': 84.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.268228530883789, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5149, 'eval_samples_per_second': 31.077, 'eval_steps_per_second': 3.885, 'epoch': 84.0}
 85%|████████████████████████████████████████████████████▋         | 170/200 [03:27<00:31,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.8929, 'grad_norm': 13.721848487854004, 'learning_rate': 1.6000000000000003e-05, 'epoch': 84.5}
{'loss': 5.1861, 'grad_norm': 6.317000865936279, 'learning_rate': 1.55e-05, 'epoch': 85.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.245833396911621, 'eval_mlm_accuracy': 0.041666666666666664, 'eval_runtime': 0.4499, 'eval_samples_per_second': 35.563, 'eval_steps_per_second': 4.445, 'epoch': 85.0}
 86%|█████████████████████████████████████████████████████▎        | 172/200 [03:29<00:27,  1.01it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1469, 'grad_norm': 11.394068717956543, 'learning_rate': 1.5e-05, 'epoch': 85.5}
{'loss': 4.9857, 'grad_norm': 10.140624046325684, 'learning_rate': 1.45e-05, 'epoch': 86.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.26111125946045, 'eval_mlm_accuracy': 0.08333333333333333, 'eval_runtime': 0.427, 'eval_samples_per_second': 37.472, 'eval_steps_per_second': 4.684, 'epoch': 86.0}
 87%|█████████████████████████████████████████████████████▉        | 174/200 [03:31<00:25,  1.03it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1585, 'grad_norm': 6.552925109863281, 'learning_rate': 1.4000000000000001e-05, 'epoch': 86.5}
{'loss': 4.675, 'grad_norm': 7.965936183929443, 'learning_rate': 1.3500000000000001e-05, 'epoch': 87.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.985677719116211, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.6452, 'eval_samples_per_second': 24.799, 'eval_steps_per_second': 3.1, 'epoch': 87.0}
 88%|██████████████████████████████████████████████████████▌       | 176/200 [03:34<00:25,  1.05s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.471, 'grad_norm': 8.726455688476562, 'learning_rate': 1.3000000000000001e-05, 'epoch': 87.5}
{'loss': 4.9023, 'grad_norm': 9.061734199523926, 'learning_rate': 1.25e-05, 'epoch': 88.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.427543640136719, 'eval_mlm_accuracy': 0.043478260869565216, 'eval_runtime': 0.5594, 'eval_samples_per_second': 28.601, 'eval_steps_per_second': 3.575, 'epoch': 88.0}
 89%|███████████████████████████████████████████████████████▏      | 178/200 [03:37<00:24,  1.09s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.9507, 'grad_norm': 8.761554718017578, 'learning_rate': 1.2e-05, 'epoch': 88.5}
{'loss': 4.5844, 'grad_norm': 14.392426490783691, 'learning_rate': 1.1500000000000002e-05, 'epoch': 89.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.874588966369629, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4315, 'eval_samples_per_second': 37.077, 'eval_steps_per_second': 4.635, 'epoch': 89.0}
 90%|███████████████████████████████████████████████████████▊      | 180/200 [03:39<00:21,  1.05s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.8965, 'grad_norm': 7.646730899810791, 'learning_rate': 1.1000000000000001e-05, 'epoch': 89.5}
{'loss': 4.4344, 'grad_norm': 9.931045532226562, 'learning_rate': 1.05e-05, 'epoch': 90.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.484375, 'eval_mlm_accuracy': 0.08333333333333333, 'eval_runtime': 0.4784, 'eval_samples_per_second': 33.446, 'eval_steps_per_second': 4.181, 'epoch': 90.0}
 91%|████████████████████████████████████████████████████████▍     | 182/200 [03:41<00:18,  1.03s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.5703, 'grad_norm': 7.448024272918701, 'learning_rate': 1e-05, 'epoch': 90.5}
{'loss': 4.8857, 'grad_norm': 7.742005348205566, 'learning_rate': 9.5e-06, 'epoch': 91.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.33203125, 'eval_mlm_accuracy': 0.043478260869565216, 'eval_runtime': 0.4307, 'eval_samples_per_second': 37.15, 'eval_steps_per_second': 4.644, 'epoch': 91.0}
 92%|█████████████████████████████████████████████████████████     | 184/200 [03:44<00:16,  1.02s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1652, 'grad_norm': 12.324115753173828, 'learning_rate': 9e-06, 'epoch': 91.5}
{'loss': 5.2697, 'grad_norm': 7.1112565994262695, 'learning_rate': 8.500000000000002e-06, 'epoch': 92.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.389223098754883, 'eval_mlm_accuracy': 0.08, 'eval_runtime': 0.5217, 'eval_samples_per_second': 30.666, 'eval_steps_per_second': 3.833, 'epoch': 92.0}
 93%|█████████████████████████████████████████████████████████▋    | 186/200 [03:47<00:14,  1.07s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.1606, 'grad_norm': 7.302429676055908, 'learning_rate': 8.000000000000001e-06, 'epoch': 92.5}
{'loss': 4.7801, 'grad_norm': 9.05555248260498, 'learning_rate': 7.5e-06, 'epoch': 93.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.07899284362793, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.423, 'eval_samples_per_second': 37.828, 'eval_steps_per_second': 4.729, 'epoch': 93.0}
 94%|██████████████████████████████████████████████████████████▎   | 188/200 [03:49<00:12,  1.05s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.0647, 'grad_norm': 8.419026374816895, 'learning_rate': 7.000000000000001e-06, 'epoch': 93.5}
{'loss': 4.9859, 'grad_norm': 10.076704978942871, 'learning_rate': 6.5000000000000004e-06, 'epoch': 94.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 9.923931121826172, 'eval_mlm_accuracy': 0.038461538461538464, 'eval_runtime': 0.3976, 'eval_samples_per_second': 40.246, 'eval_steps_per_second': 5.031, 'epoch': 94.0}
 95%|██████████████████████████████████████████████████████████▉   | 190/200 [03:51<00:10,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.5951, 'grad_norm': 10.202884674072266, 'learning_rate': 6e-06, 'epoch': 94.5}
{'loss': 4.8542, 'grad_norm': 10.191356658935547, 'learning_rate': 5.500000000000001e-06, 'epoch': 95.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.731128692626953, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.5258, 'eval_samples_per_second': 30.429, 'eval_steps_per_second': 3.804, 'epoch': 95.0}
 96%|███████████████████████████████████████████████████████████▌  | 192/200 [03:54<00:08,  1.07s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.9172, 'grad_norm': 9.881461143493652, 'learning_rate': 5e-06, 'epoch': 95.5}
{'loss': 5.0312, 'grad_norm': 13.249878883361816, 'learning_rate': 4.5e-06, 'epoch': 96.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 11.407552719116211, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4206, 'eval_samples_per_second': 38.041, 'eval_steps_per_second': 4.755, 'epoch': 96.0}
 97%|████████████████████████████████████████████████████████████▏ | 194/200 [03:56<00:06,  1.01s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.5017, 'grad_norm': 11.219624519348145, 'learning_rate': 4.000000000000001e-06, 'epoch': 96.5}
{'loss': 5.1046, 'grad_norm': 8.703749656677246, 'learning_rate': 3.5000000000000004e-06, 'epoch': 97.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 8.766658782958984, 'eval_mlm_accuracy': 0.047619047619047616, 'eval_runtime': 0.5286, 'eval_samples_per_second': 30.271, 'eval_steps_per_second': 3.784, 'epoch': 97.0}
 98%|████████████████████████████████████████████████████████████▊ | 196/200 [03:59<00:04,  1.04s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 4.858, 'grad_norm': 10.105255126953125, 'learning_rate': 3e-06, 'epoch': 97.5}
{'loss': 5.2411, 'grad_norm': 6.795188903808594, 'learning_rate': 2.5e-06, 'epoch': 98.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.769922256469727, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4759, 'eval_samples_per_second': 33.621, 'eval_steps_per_second': 4.203, 'epoch': 98.0}
 99%|█████████████████████████████████████████████████████████████▍| 198/200 [04:01<00:02,  1.00s/it]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3477, 'grad_norm': 8.13162612915039, 'learning_rate': 2.0000000000000003e-06, 'epoch': 98.5}
{'loss': 4.2478, 'grad_norm': 12.700050354003906, 'learning_rate': 1.5e-06, 'epoch': 99.0}
  return forward_call(*args, **kwargs)                                                               
{'eval_loss': 10.405858993530273, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4417, 'eval_samples_per_second': 36.222, 'eval_steps_per_second': 4.528, 'epoch': 99.0}
100%|██████████████████████████████████████████████████████████████| 200/200 [04:05<00:00,  1.23s/it]
{'loss': 5.1441, 'grad_norm': 10.478466033935547, 'learning_rate': 1.0000000000000002e-06, 'epoch': 99.5}
{'loss': 5.2904, 'grad_norm': 9.228802680969238, 'learning_rate': 5.000000000000001e-07, 'epoch': 100.0}
                                                                                                     
{'eval_loss': 11.79600715637207, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.4952, 'eval_samples_per_second': 32.31, 'eval_steps_per_second': 4.039, 'epoch': 100.0}
{'train_runtime': 246.7923, 'train_samples_per_second': 6.483, 'train_steps_per_second': 0.81, 'train_loss': 6.1206758379936215, 'epoch': 100.0}
Training finished.
Saving final model to ./overfit_test_model\final_model
Model and tokenizer saved.
