

[DEBUG_CALLBACK] --- on_train_begin: Training is starting! ---
  0%|                                                                                                                | 0/2465091 [00:00<?, ?it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.

[DEBUG_CALLBACK] --- on_epoch_begin: Starting Epoch 0 ---
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 0 --
  return forward_call(*args, **kwargs)
[DEBUG_CALLBACK] -- on_step_end: Finished train step 1 --
  0%|                                                                                                   | 10/2465091 [00:56<693:54:04,  1.01s/it]Traceback (most recent call last):
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 1 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 2 --
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 2 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 3 --
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 3 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 4 --
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 4 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 5 --
{'loss': 15.6292, 'grad_norm': 9.87547492980957, 'learning_rate': 4.9999918867092535e-05, 'epoch': 0.0}
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 5 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 6 --
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 6 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 7 --
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 7 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 8 --
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 8 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 9 --
[DEBUG_CALLBACK] -- on_step_begin: Starting train step 9 --
[DEBUG_CALLBACK] -- on_step_end: Finished train step 10 --
{'loss': 17.2689, 'grad_norm': 8.611835479736328, 'learning_rate': 4.99998174509582e-05, 'epoch': 0.0}
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\train_model.py", line 64, in <module>397 [01:25<440:23:36,  2.17s/it]
    main()
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\train_model.py", line 48, in main
    run_training(
  File "c:\Users\omrid\Desktop\university\intelexsus\sandbox\sanskrit\model\training_utils.py", line 145, in run_training
    compute_metrics=compute_metrics if eval_dataset else None,
    ^^^^^^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 2237, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 2660, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 3133, in _maybe_log_save_evaluate
    metrics = self._evaluate(trial, ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 3082, in _evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 4242, in evaluate
    output = eval_loop(
             ^^^^^^^^^^
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer.py", line 4490, in evaluation_loop
    all_labels.to_cpu_and_numpy()
  File "C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\transformers\trainer_pt_utils.py", line 321, in to_cpu_and_numpy
    def to_cpu_and_numpy(self) -> None:

KeyboardInterrupt
