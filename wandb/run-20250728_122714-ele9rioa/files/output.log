  0%|                                                                                                                    | 0/900 [00:00<?, ?it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
  6%|█████▉                                                                                                     | 50/900 [00:04<01:02, 13.71it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 10.2527, 'grad_norm': 6.478953838348389, 'learning_rate': 4.9500000000000004e-05, 'epoch': 1.67}
{'loss': 10.1223, 'grad_norm': 7.243375778198242, 'learning_rate': 4.894444444444445e-05, 'epoch': 3.33}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 10.095399856567383, 'eval_mlm_accuracy': 0.09090909090909091, 'eval_runtime': 0.2581, 'eval_samples_per_second': 38.752, 'eval_steps_per_second': 7.75, 'epoch': 3.33}
{'loss': 10.0137, 'grad_norm': 8.090278625488281, 'learning_rate': 4.844444444444445e-05, 'epoch': 5.0}
{'loss': 9.8208, 'grad_norm': 8.383401870727539, 'learning_rate': 4.7888888888888886e-05, 'epoch': 6.67}
{'eval_loss': 10.07118034362793, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2417, 'eval_samples_per_second': 41.379, 'eval_steps_per_second': 8.276, 'epoch': 6.67}
{'loss': 9.6053, 'grad_norm': 6.676814079284668, 'learning_rate': 4.7333333333333336e-05, 'epoch': 8.33}
 11%|███████████▊                                                                                              | 100/900 [00:08<00:58, 13.67it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 9.3264, 'grad_norm': 7.109482288360596, 'learning_rate': 4.677777777777778e-05, 'epoch': 10.0}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 9.924478530883789, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2657, 'eval_samples_per_second': 37.631, 'eval_steps_per_second': 7.526, 'epoch': 10.0}
{'loss': 9.3302, 'grad_norm': 5.923762321472168, 'learning_rate': 4.6222222222222224e-05, 'epoch': 11.67}
{'loss': 9.1169, 'grad_norm': 6.48275089263916, 'learning_rate': 4.566666666666667e-05, 'epoch': 13.33}
{'eval_loss': 9.14453125, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2884, 'eval_samples_per_second': 34.674, 'eval_steps_per_second': 6.935, 'epoch': 13.33}
{'loss': 8.8613, 'grad_norm': 8.821185111999512, 'learning_rate': 4.511111111111112e-05, 'epoch': 15.0}
{'loss': 8.7832, 'grad_norm': 8.065925598144531, 'learning_rate': 4.4555555555555555e-05, 'epoch': 16.67}
{'eval_loss': nan, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.1972, 'eval_samples_per_second': 50.719, 'eval_steps_per_second': 10.144, 'epoch': 16.67}
 17%|█████████████████▋                                                                                        | 150/900 [00:12<00:58, 12.75it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 8.6834, 'grad_norm': 6.856151103973389, 'learning_rate': 4.4000000000000006e-05, 'epoch': 18.33}
{'loss': 8.6212, 'grad_norm': 9.13146686553955, 'learning_rate': 4.344444444444445e-05, 'epoch': 20.0}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 10.179947853088379, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2361, 'eval_samples_per_second': 42.347, 'eval_steps_per_second': 8.469, 'epoch': 20.0}
{'loss': 8.4887, 'grad_norm': 6.188681602478027, 'learning_rate': 4.2888888888888886e-05, 'epoch': 21.67}
{'loss': 8.129, 'grad_norm': 6.103257179260254, 'learning_rate': 4.233333333333334e-05, 'epoch': 23.33}
{'eval_loss': 9.326250076293945, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2459, 'eval_samples_per_second': 40.67, 'eval_steps_per_second': 8.134, 'epoch': 23.33}
{'loss': 7.9799, 'grad_norm': 8.577510833740234, 'learning_rate': 4.177777777777778e-05, 'epoch': 25.0}
 22%|███████████████████████▌                                                                                  | 200/900 [00:17<00:49, 14.22it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.9542, 'grad_norm': 5.50226354598999, 'learning_rate': 4.1222222222222224e-05, 'epoch': 26.67}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 10.212499618530273, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.29, 'eval_samples_per_second': 34.487, 'eval_steps_per_second': 6.897, 'epoch': 26.67}
{'loss': 7.6735, 'grad_norm': 5.890054225921631, 'learning_rate': 4.066666666666667e-05, 'epoch': 28.33}
{'loss': 7.8542, 'grad_norm': 9.368635177612305, 'learning_rate': 4.011111111111111e-05, 'epoch': 30.0}
{'eval_loss': 9.29847526550293, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2808, 'eval_samples_per_second': 35.606, 'eval_steps_per_second': 7.121, 'epoch': 30.0}
{'loss': 7.4036, 'grad_norm': 8.522133827209473, 'learning_rate': 3.9555555555555556e-05, 'epoch': 31.67}
{'loss': 7.3695, 'grad_norm': 5.145172595977783, 'learning_rate': 3.9000000000000006e-05, 'epoch': 33.33}
{'eval_loss': 10.020659446716309, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2005, 'eval_samples_per_second': 49.868, 'eval_steps_per_second': 9.974, 'epoch': 33.33}
 28%|█████████████████████████████▍                                                                            | 250/900 [00:21<00:52, 12.39it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 7.2501, 'grad_norm': 6.809545516967773, 'learning_rate': 3.844444444444444e-05, 'epoch': 35.0}
{'loss': 7.1777, 'grad_norm': 6.463479518890381, 'learning_rate': 3.7888888888888894e-05, 'epoch': 36.67}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 9.438020706176758, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2424, 'eval_samples_per_second': 41.248, 'eval_steps_per_second': 8.25, 'epoch': 36.67}
{'loss': 7.0668, 'grad_norm': 5.132267951965332, 'learning_rate': 3.733333333333334e-05, 'epoch': 38.33}
{'loss': 7.0291, 'grad_norm': 5.765217304229736, 'learning_rate': 3.677777777777778e-05, 'epoch': 40.0}
{'eval_loss': 9.719297409057617, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2944, 'eval_samples_per_second': 33.962, 'eval_steps_per_second': 6.792, 'epoch': 40.0}
{'loss': 6.8585, 'grad_norm': 5.467109680175781, 'learning_rate': 3.6222222222222225e-05, 'epoch': 41.67}
 33%|███████████████████████████████████▎                                                                      | 300/900 [00:25<00:41, 14.51it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.6412, 'grad_norm': 5.351301193237305, 'learning_rate': 3.566666666666667e-05, 'epoch': 43.33}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 8.457877159118652, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.3246, 'eval_samples_per_second': 30.809, 'eval_steps_per_second': 6.162, 'epoch': 43.33}
{'loss': 6.8651, 'grad_norm': 7.082972049713135, 'learning_rate': 3.511111111111111e-05, 'epoch': 45.0}
{'loss': 6.6555, 'grad_norm': 5.693212985992432, 'learning_rate': 3.4555555555555556e-05, 'epoch': 46.67}
{'eval_loss': 8.956684112548828, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2597, 'eval_samples_per_second': 38.502, 'eval_steps_per_second': 7.7, 'epoch': 46.67}
{'loss': 6.5412, 'grad_norm': 5.348328590393066, 'learning_rate': 3.4000000000000007e-05, 'epoch': 48.33}
{'loss': 6.4774, 'grad_norm': 6.752690315246582, 'learning_rate': 3.3444444444444443e-05, 'epoch': 50.0}
{'eval_loss': 10.784375190734863, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.1705, 'eval_samples_per_second': 58.638, 'eval_steps_per_second': 11.728, 'epoch': 50.0}
 39%|█████████████████████████████████████████▏                                                                | 350/900 [00:29<00:41, 13.30it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 6.3191, 'grad_norm': 5.531137943267822, 'learning_rate': 3.2888888888888894e-05, 'epoch': 51.67}
{'loss': 6.4152, 'grad_norm': 8.032362937927246, 'learning_rate': 3.233333333333333e-05, 'epoch': 53.33}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 8.594843864440918, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2441, 'eval_samples_per_second': 40.969, 'eval_steps_per_second': 8.194, 'epoch': 53.33}
{'loss': 6.295, 'grad_norm': 8.620088577270508, 'learning_rate': 3.177777777777778e-05, 'epoch': 55.0}
{'loss': 6.1254, 'grad_norm': 6.963996887207031, 'learning_rate': 3.1222222222222225e-05, 'epoch': 56.67}
{'eval_loss': 9.104101181030273, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2651, 'eval_samples_per_second': 37.729, 'eval_steps_per_second': 7.546, 'epoch': 56.67}
{'loss': 5.9933, 'grad_norm': 5.822023391723633, 'learning_rate': 3.066666666666667e-05, 'epoch': 58.33}
 44%|███████████████████████████████████████████████                                                           | 400/900 [00:34<00:33, 14.90it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.9617, 'grad_norm': 6.642930030822754, 'learning_rate': 3.0111111111111113e-05, 'epoch': 60.0}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 9.69921875, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2436, 'eval_samples_per_second': 41.056, 'eval_steps_per_second': 8.211, 'epoch': 60.0}
{'loss': 6.0784, 'grad_norm': 5.348316192626953, 'learning_rate': 2.955555555555556e-05, 'epoch': 61.67}
{'loss': 5.6867, 'grad_norm': 7.39573335647583, 'learning_rate': 2.9e-05, 'epoch': 63.33}
{'eval_loss': 9.475446701049805, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.3205, 'eval_samples_per_second': 31.196, 'eval_steps_per_second': 6.239, 'epoch': 63.33}
{'loss': 5.8493, 'grad_norm': 6.388735294342041, 'learning_rate': 2.8444444444444447e-05, 'epoch': 65.0}
{'loss': 5.7874, 'grad_norm': 5.606215476989746, 'learning_rate': 2.788888888888889e-05, 'epoch': 66.67}
{'eval_loss': 8.303472518920898, 'eval_mlm_accuracy': 0.09090909090909091, 'eval_runtime': 0.1687, 'eval_samples_per_second': 59.289, 'eval_steps_per_second': 11.858, 'epoch': 66.67}
 50%|█████████████████████████████████████████████████████                                                     | 450/900 [00:38<00:34, 13.08it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.7271, 'grad_norm': 5.118374824523926, 'learning_rate': 2.733333333333333e-05, 'epoch': 68.33}
{'loss': 5.8823, 'grad_norm': 5.322256088256836, 'learning_rate': 2.677777777777778e-05, 'epoch': 70.0}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 9.45882797241211, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2566, 'eval_samples_per_second': 38.965, 'eval_steps_per_second': 7.793, 'epoch': 70.0}
{'loss': 5.6567, 'grad_norm': 6.621962070465088, 'learning_rate': 2.6222222222222226e-05, 'epoch': 71.67}
{'loss': 5.6535, 'grad_norm': 5.405853271484375, 'learning_rate': 2.5666666666666666e-05, 'epoch': 73.33}
{'eval_loss': 10.621484756469727, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2481, 'eval_samples_per_second': 40.31, 'eval_steps_per_second': 8.062, 'epoch': 73.33}
{'loss': 5.771, 'grad_norm': 7.210809230804443, 'learning_rate': 2.5111111111111113e-05, 'epoch': 75.0}
 56%|██████████████████████████████████████████████████████████▉                                               | 500/900 [00:42<00:26, 15.10it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.75, 'grad_norm': 5.594958782196045, 'learning_rate': 2.4555555555555557e-05, 'epoch': 76.67}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 7.792578220367432, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2988, 'eval_samples_per_second': 33.468, 'eval_steps_per_second': 6.694, 'epoch': 76.67}
{'loss': 5.6618, 'grad_norm': 5.3759660720825195, 'learning_rate': 2.4e-05, 'epoch': 78.33}
{'loss': 5.6734, 'grad_norm': 6.3773698806762695, 'learning_rate': 2.3444444444444448e-05, 'epoch': 80.0}
{'eval_loss': 7.926042079925537, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.235, 'eval_samples_per_second': 42.546, 'eval_steps_per_second': 8.509, 'epoch': 80.0}
{'loss': 5.6724, 'grad_norm': 5.422626495361328, 'learning_rate': 2.288888888888889e-05, 'epoch': 81.67}
{'loss': 5.8393, 'grad_norm': 4.796034336090088, 'learning_rate': 2.2333333333333335e-05, 'epoch': 83.33}
{'eval_loss': nan, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.1866, 'eval_samples_per_second': 53.576, 'eval_steps_per_second': 10.715, 'epoch': 83.33}
 61%|████████████████████████████████████████████████████████████████▊                                         | 550/900 [00:46<00:27, 12.56it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.7608, 'grad_norm': 6.740036487579346, 'learning_rate': 2.177777777777778e-05, 'epoch': 85.0}
{'loss': 5.7447, 'grad_norm': 4.433003902435303, 'learning_rate': 2.1222222222222223e-05, 'epoch': 86.67}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 6.1544270515441895, 'eval_mlm_accuracy': 0.1111111111111111, 'eval_runtime': 0.2357, 'eval_samples_per_second': 42.431, 'eval_steps_per_second': 8.486, 'epoch': 86.67}
{'loss': 5.6872, 'grad_norm': 5.327884197235107, 'learning_rate': 2.0666666666666666e-05, 'epoch': 88.33}
{'loss': 5.7183, 'grad_norm': 5.953467845916748, 'learning_rate': 2.011111111111111e-05, 'epoch': 90.0}
{'eval_loss': 8.655858993530273, 'eval_mlm_accuracy': 0.14285714285714285, 'eval_runtime': 0.3399, 'eval_samples_per_second': 29.416, 'eval_steps_per_second': 5.883, 'epoch': 90.0}
{'loss': 5.4209, 'grad_norm': 7.79280424118042, 'learning_rate': 1.9555555555555557e-05, 'epoch': 91.67}
 67%|██████████████████████████████████████████████████████████████████████▋                                   | 600/900 [00:50<00:19, 15.58it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.5258, 'grad_norm': 5.2453742027282715, 'learning_rate': 1.9e-05, 'epoch': 93.33}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 6.877890586853027, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.242, 'eval_samples_per_second': 41.324, 'eval_steps_per_second': 8.265, 'epoch': 93.33}
{'loss': 5.5561, 'grad_norm': 6.579466819763184, 'learning_rate': 1.8444444444444445e-05, 'epoch': 95.0}
{'loss': 5.5968, 'grad_norm': 7.138526916503906, 'learning_rate': 1.788888888888889e-05, 'epoch': 96.67}
{'eval_loss': 8.629240989685059, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2838, 'eval_samples_per_second': 35.234, 'eval_steps_per_second': 7.047, 'epoch': 96.67}
{'loss': 5.3492, 'grad_norm': 6.120532512664795, 'learning_rate': 1.7333333333333336e-05, 'epoch': 98.33}
{'loss': 5.5615, 'grad_norm': 6.782746315002441, 'learning_rate': 1.677777777777778e-05, 'epoch': 100.0}
{'eval_loss': 9.918749809265137, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.1672, 'eval_samples_per_second': 59.799, 'eval_steps_per_second': 11.96, 'epoch': 100.0}
 72%|████████████████████████████████████████████████████████████████████████████▌                             | 650/900 [00:54<00:18, 13.67it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3636, 'grad_norm': 5.971409320831299, 'learning_rate': 1.6222222222222223e-05, 'epoch': 101.67}
{'loss': 5.1874, 'grad_norm': 4.679238796234131, 'learning_rate': 1.5666666666666667e-05, 'epoch': 103.33}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 6.878013610839844, 'eval_mlm_accuracy': 0.125, 'eval_runtime': 0.2638, 'eval_samples_per_second': 37.91, 'eval_steps_per_second': 7.582, 'epoch': 103.33}
{'loss': 5.3968, 'grad_norm': 6.812119007110596, 'learning_rate': 1.5111111111111112e-05, 'epoch': 105.0}
{'loss': 5.4395, 'grad_norm': 5.644629955291748, 'learning_rate': 1.4555555555555556e-05, 'epoch': 106.67}
{'eval_loss': 10.213203430175781, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2381, 'eval_samples_per_second': 41.999, 'eval_steps_per_second': 8.4, 'epoch': 106.67}
{'loss': 5.2646, 'grad_norm': 6.48887300491333, 'learning_rate': 1.4000000000000001e-05, 'epoch': 108.33}
 78%|██████████████████████████████████████████████████████████████████████████████████▍                       | 700/900 [00:59<00:13, 15.31it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.2877, 'grad_norm': 6.4532294273376465, 'learning_rate': 1.3444444444444445e-05, 'epoch': 110.0}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 8.311458587646484, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2818, 'eval_samples_per_second': 35.49, 'eval_steps_per_second': 7.098, 'epoch': 110.0}
{'loss': 5.4798, 'grad_norm': 5.801076412200928, 'learning_rate': 1.2888888888888889e-05, 'epoch': 111.67}
{'loss': 5.3041, 'grad_norm': 4.421003818511963, 'learning_rate': 1.2333333333333334e-05, 'epoch': 113.33}
{'eval_loss': 7.6526994705200195, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2344, 'eval_samples_per_second': 42.657, 'eval_steps_per_second': 8.531, 'epoch': 113.33}
{'loss': 5.5021, 'grad_norm': 6.206284999847412, 'learning_rate': 1.1777777777777778e-05, 'epoch': 115.0}
{'loss': 5.4932, 'grad_norm': 4.827033042907715, 'learning_rate': 1.1222222222222224e-05, 'epoch': 116.67}
{'eval_loss': nan, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.1735, 'eval_samples_per_second': 57.641, 'eval_steps_per_second': 11.528, 'epoch': 116.67}
 83%|████████████████████████████████████████████████████████████████████████████████████████▎                 | 750/900 [01:03<00:10, 13.66it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.3208, 'grad_norm': 7.112532138824463, 'learning_rate': 1.0666666666666667e-05, 'epoch': 118.33}
{'loss': 5.2098, 'grad_norm': 10.56112289428711, 'learning_rate': 1.0111111111111111e-05, 'epoch': 120.0}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 7.748893737792969, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2637, 'eval_samples_per_second': 37.923, 'eval_steps_per_second': 7.585, 'epoch': 120.0}
{'loss': 5.5637, 'grad_norm': 6.864416122436523, 'learning_rate': 9.555555555555556e-06, 'epoch': 121.67}
{'loss': 5.5862, 'grad_norm': 5.597740650177002, 'learning_rate': 9e-06, 'epoch': 123.33}
{'eval_loss': 11.691144943237305, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2874, 'eval_samples_per_second': 34.792, 'eval_steps_per_second': 6.958, 'epoch': 123.33}
{'loss': 5.3447, 'grad_norm': 5.9036030769348145, 'learning_rate': 8.444444444444446e-06, 'epoch': 125.0}
 89%|██████████████████████████████████████████████████████████████████████████████████████████████▏           | 800/900 [01:07<00:06, 14.69it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.358, 'grad_norm': 8.025106430053711, 'learning_rate': 7.88888888888889e-06, 'epoch': 126.67}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 7.908593654632568, 'eval_mlm_accuracy': 0.1, 'eval_runtime': 0.2311, 'eval_samples_per_second': 43.275, 'eval_steps_per_second': 8.655, 'epoch': 126.67}
{'loss': 5.4593, 'grad_norm': 4.672082424163818, 'learning_rate': 7.333333333333334e-06, 'epoch': 128.33}
{'loss': 5.5265, 'grad_norm': 8.032757759094238, 'learning_rate': 6.777777777777779e-06, 'epoch': 130.0}
{'eval_loss': 11.05859375, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.281, 'eval_samples_per_second': 35.589, 'eval_steps_per_second': 7.118, 'epoch': 130.0}
{'loss': 5.5572, 'grad_norm': 7.221872329711914, 'learning_rate': 6.222222222222222e-06, 'epoch': 131.67}
{'loss': 5.709, 'grad_norm': 6.511392116546631, 'learning_rate': 5.666666666666667e-06, 'epoch': 133.33}
{'eval_loss': nan, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.1697, 'eval_samples_per_second': 58.916, 'eval_steps_per_second': 11.783, 'epoch': 133.33}
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████      | 850/900 [01:11<00:04, 12.37it/s]C:\Users\omrid\miniconda3\envs\INTELEXSUS\Lib\site-packages\torch\nn\modules\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
{'loss': 5.521, 'grad_norm': 12.335561752319336, 'learning_rate': 5.1111111111111115e-06, 'epoch': 135.0}
{'loss': 5.3031, 'grad_norm': 6.231764316558838, 'learning_rate': 4.555555555555556e-06, 'epoch': 136.67}
  return forward_call(*args, **kwargs)                                                                                                           
{'eval_loss': 6.113839149475098, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2839, 'eval_samples_per_second': 35.225, 'eval_steps_per_second': 7.045, 'epoch': 136.67}
{'loss': 5.4887, 'grad_norm': 5.015449047088623, 'learning_rate': 4.000000000000001e-06, 'epoch': 138.33}
{'loss': 5.1611, 'grad_norm': 9.097190856933594, 'learning_rate': 3.4444444444444444e-06, 'epoch': 140.0}
{'eval_loss': 8.377968788146973, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2836, 'eval_samples_per_second': 35.262, 'eval_steps_per_second': 7.052, 'epoch': 140.0}
{'loss': 5.4764, 'grad_norm': 4.348885536193848, 'learning_rate': 2.888888888888889e-06, 'epoch': 141.67}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 900/900 [01:16<00:00, 11.80it/s]
{'loss': 5.5757, 'grad_norm': 5.0210394859313965, 'learning_rate': 2.3333333333333336e-06, 'epoch': 143.33}
                                                                                                                                                 
{'eval_loss': 10.039583206176758, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.2778, 'eval_samples_per_second': 35.993, 'eval_steps_per_second': 7.199, 'epoch': 143.33}
{'loss': 5.2796, 'grad_norm': 6.376599311828613, 'learning_rate': 1.777777777777778e-06, 'epoch': 145.0}
{'loss': 5.4732, 'grad_norm': 4.981131076812744, 'learning_rate': 1.2222222222222223e-06, 'epoch': 146.67}
{'eval_loss': 8.788759231567383, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.294, 'eval_samples_per_second': 34.017, 'eval_steps_per_second': 6.803, 'epoch': 146.67}
{'loss': 5.5379, 'grad_norm': 7.096765518188477, 'learning_rate': 6.666666666666667e-07, 'epoch': 148.33}
{'loss': 5.3357, 'grad_norm': 8.653481483459473, 'learning_rate': 1.1111111111111112e-07, 'epoch': 150.0}
{'eval_loss': 9.038325309753418, 'eval_mlm_accuracy': 0.0, 'eval_runtime': 0.1631, 'eval_samples_per_second': 61.305, 'eval_steps_per_second': 12.261, 'epoch': 150.0}
{'train_runtime': 77.7856, 'train_samples_per_second': 173.554, 'train_steps_per_second': 11.57, 'train_loss': 6.446438280741374, 'epoch': 150.0}
Training finished.
Saving final model to ./overfit_test_model\final_model
Model and tokenizer saved.
--- Overfitting Test Finished ---
