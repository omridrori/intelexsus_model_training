dataset_dir: data\downstream_tasks\DharmaBench\Tibetan\SCCT
text_fields: [text]
label_field: label
models:
  - google-bert/bert-base-multilingual-cased
  - OMRIDRORI/mbert-tibetan-continual-unicode-240k
convert_to_wylie: auto
num_epochs: 3
learning_rate: 2.0e-5
batch_size: 8
eval_steps: 50
save_total_limit: 2
files: [train.jsonl, test.jsonl]
f1_average: weighted


